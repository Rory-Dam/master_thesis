{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "from matplotlib.tri import Triangulation\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(file_name):\n",
    "    grid_search_results = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            if line[0:4] == '----':\n",
    "                grid_search_results.append([])\n",
    "                continue\n",
    "\n",
    "            if line[0] == '(':\n",
    "                fixed_line = '[' + line.strip().replace(') (', '), (') + ']'\n",
    "                params = ast.literal_eval(fixed_line)\n",
    "                nested = [list(zip(key.split(','), np.array(val).flatten())) for (key, val) in params]\n",
    "                unnested = [item for sublist in nested for item in sublist]\n",
    "                grid_search_results[-1].append({key: val for (key, val) in unnested})\n",
    "                grid_search_results[-1].append([])\n",
    "                continue\n",
    "\n",
    "            result = line\n",
    "\n",
    "            if result[0] == '[':\n",
    "                grid_search_results[-1][-1].append(ast.literal_eval(result))\n",
    "                continue\n",
    "\n",
    "    grid_search_results = [(params, np.array(values)) for params, values in grid_search_results]\n",
    "    return grid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_res = parse_results('grid_search_results/hyp_broad_search_50_cutoff.txt')\n",
    "# euc_res = parse_results('grid_search_results/tom_euc_overall-liking_400.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 5, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_params = np.array([p for p, _ in hyp_res])\n",
    "hyp_values = np.array([v for _, v in hyp_res])\n",
    "\n",
    "# euc_params = np.array([p for p, _ in euc_res])\n",
    "# euc_values = np.array([v for _, v in euc_res])\n",
    "\n",
    "hyp_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 5, 50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last = hyp_values[-1]\n",
    "# repeated_last = np.repeat(last[np.newaxis, ...], 9, axis=0)\n",
    "extended_hyp = np.concatenate((hyp_values, hyp_values[-9:]), axis=0)\n",
    "\n",
    "extended_hyp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71892392, 0.82833852, 0.8776104 , 0.90593009, 0.92502355,\n",
       "       0.93885726, 0.94905978, 0.95653569, 0.96234253, 0.96683899,\n",
       "       0.9705315 , 0.97367664, 0.97633575, 0.97854154, 0.98021196,\n",
       "       0.98209436, 0.98364224, 0.98513093, 0.98630006, 0.98729792,\n",
       "       0.98830944, 0.98896138, 0.98974719, 0.99057806, 0.99121302,\n",
       "       0.99190675, 0.99240638, 0.99276035, 0.99340857, 0.99384069,\n",
       "       0.99437551, 0.9947761 , 0.99519633, 0.99546848, 0.99585908,\n",
       "       0.99624004, 0.99651976, 0.99685836, 0.99705058, 0.99745761,\n",
       "       0.99786952, 0.99804287, 0.99825635, 0.99861292, 0.99879301,\n",
       "       0.99916525, 0.99929335, 0.99951826, 0.99978482, 1.        ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(extended_hyp.mean(axis=1).mean(axis=0) / extended_hyp.mean(axis=1).mean(axis=0).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36824 0.35638 0.31898 0.36934 0.3589  0.32558 0.37004 0.35972 0.32844]\n",
      "[0.36824 0.36934 0.37004]\n",
      "[0.37034 0.37182 0.37262]\n"
     ]
    }
   ],
   "source": [
    "round_ext_hyp = np.round(extended_hyp, 4)\n",
    "\n",
    "# print(round_ext_hyp.mean(axis=1)[:,-1][:27][:9].mean())\n",
    "# print(round_ext_hyp.mean(axis=1)[:,-1][:27][9:18].mean())\n",
    "# print(round_ext_hyp.mean(axis=1)[:,-1][27:54][:9].mean())\n",
    "# print(round_ext_hyp.mean(axis=1)[:,-1][27:54][9:18].mean())\n",
    "\n",
    "print(round_ext_hyp.mean(axis=1)[:,-1][:27][18:][::3])\n",
    "\n",
    "print(round_ext_hyp.mean(axis=1)[:,-1][27:54][18:][::3])\n",
    "\n",
    "# print(round_ext_hyp.mean(axis=1)[:,-1][54:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'model_type': ['hyp'],\n",
    "    'num_hidden_layers': [1],\n",
    "    'layer_size': [256],\n",
    "    'lr': [0.01],\n",
    "    'weight_decay': [0.001],\n",
    "    'batch_size': [1024],\n",
    "    'epochs': [50],\n",
    "    'curvature': [-1]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
