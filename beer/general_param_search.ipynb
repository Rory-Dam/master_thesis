{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from hypll import nn as hnn\n",
    "from hypll.tensors import TangentTensor\n",
    "from hypll.optim import RiemannianAdam\n",
    "from hypll.manifolds.poincare_ball import Curvature, PoincareBall\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "AROMA = ['A_malt_all', 'A_malt_grain', 'A_malt_bread', 'A_malt_cara',\n",
    "'A_malt_burn', 'A_hops_all', 'A_hops_citrus', 'A_hops_tropical',\n",
    "'A_hops_noble', 'A_hops_woody', 'A_esters_all', 'A_esters_ethac',\n",
    "'A_esters_isoaa', 'A_esters_flower', 'A_esters_fruity']\n",
    "\n",
    "FLAVOUR = ['F_malt_all', 'F_malt_grain', 'F_malt_bread', 'F_malt_cara',\n",
    "'F_malt_burn', 'F_hops_all', 'F_hops_citrus', 'F_hops_tropical',\n",
    "'F_hops_noble', 'F_hops_woody', 'F_esters_all', 'F_esters_ethac',\n",
    "'F_esters_isoaa', 'F_esters_flower', 'F_esters_fruity']\n",
    "\n",
    "BOTH = ['A_malt_all', 'A_malt_grain', 'A_malt_bread', 'A_malt_cara',\n",
    "'A_malt_burn', 'A_hops_all', 'A_hops_citrus', 'A_hops_tropical',\n",
    "'A_hops_noble', 'A_hops_woody', 'A_esters_all', 'A_esters_ethac',\n",
    "'A_esters_isoaa', 'A_esters_flower', 'A_esters_fruity', 'F_malt_all',\n",
    "'F_malt_grain', 'F_malt_bread', 'F_malt_cara', 'F_malt_burn',\n",
    "'F_hops_all', 'F_hops_citrus', 'F_hops_tropical', 'F_hops_noble',\n",
    "'F_hops_woody', 'F_esters_all', 'F_esters_ethac', 'F_esters_isoaa',\n",
    "'F_esters_flower', 'F_esters_fruity']\n",
    "\n",
    "REST = ['acidity', 'bitternes','sweetness', 'X4vg', 'diacetyl', 'dms',\n",
    "'metallic', 'stale_hops', 't2n', 'orange', 'coriander', 'clove', 'lactic',\n",
    "'acetic', 'barnyard', 'alcohol', 'aftertaste', 'body', 'co2', 'overall']\n",
    "\n",
    "ALL = ['A_malt_all', 'A_malt_grain', 'A_malt_bread', 'A_malt_cara',\n",
    "'A_malt_burn', 'A_hops_all', 'A_hops_citrus', 'A_hops_tropical',\n",
    "'A_hops_noble', 'A_hops_woody', 'A_esters_all', 'A_esters_ethac',\n",
    "'A_esters_isoaa', 'A_esters_flower', 'A_esters_fruity', 'F_malt_all',\n",
    "'F_malt_grain', 'F_malt_bread', 'F_malt_cara', 'F_malt_burn',\n",
    "'F_hops_all', 'F_hops_citrus', 'F_hops_tropical', 'F_hops_noble',\n",
    "'F_hops_woody', 'F_esters_all', 'F_esters_ethac', 'F_esters_isoaa',\n",
    "'F_esters_flower', 'F_esters_fruity', 'acidity', 'bitternes',\n",
    "'sweetness', 'X4vg', 'diacetyl', 'dms', 'metallic', 'stale_hops', 't2n',\n",
    "'orange', 'coriander', 'clove', 'lactic', 'acetic', 'barnyard',\n",
    "'alcohol', 'aftertaste', 'body', 'co2', 'overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLS = ['overall']\n",
    "# LABEL_COLS = ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((175, 231), (175, 1), (175, 231), (175, 1), (75, 231), (75, 1))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_X = pd.read_csv('../data/beer_features_train_samples_small.csv', index_col=0)\n",
    "# df_train_y = pd.read_csv('../data/beer_labels_panel_train_samples_small.csv', index_col=0)[LABEL_COLS]\n",
    "df_train_X = pd.read_csv('../data/beer_features_train.csv', index_col=0)\n",
    "df_train_y = pd.read_csv('../data/beer_labels_panel_train.csv', index_col=0)[LABEL_COLS]\n",
    "df_val_X = pd.read_csv('../data/beer_features_train.csv', index_col=0)\n",
    "df_val_y = pd.read_csv('../data/beer_labels_panel_train.csv', index_col=0)[LABEL_COLS]\n",
    "df_test_X = pd.read_csv('../data/beer_features_test.csv', index_col=0)\n",
    "df_test_y = pd.read_csv('../data/beer_labels_panel_test.csv', index_col=0)[LABEL_COLS]\n",
    "\n",
    "train_X = df_train_X.values\n",
    "train_y = df_train_y.values\n",
    "val_X = df_val_X.values\n",
    "val_y = df_val_y.values\n",
    "test_X = df_test_X.values\n",
    "test_y = df_test_y.values\n",
    "\n",
    "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['overall'], dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_malt_all</th>\n",
       "      <th>A_malt_grain</th>\n",
       "      <th>A_malt_bread</th>\n",
       "      <th>A_malt_cara</th>\n",
       "      <th>A_malt_burn</th>\n",
       "      <th>A_hops_all</th>\n",
       "      <th>A_hops_citrus</th>\n",
       "      <th>A_hops_tropical</th>\n",
       "      <th>A_hops_noble</th>\n",
       "      <th>A_hops_woody</th>\n",
       "      <th>...</th>\n",
       "      <th>coriander</th>\n",
       "      <th>clove</th>\n",
       "      <th>lactic</th>\n",
       "      <th>acetic</th>\n",
       "      <th>barnyard</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>body</th>\n",
       "      <th>co2</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.905714</td>\n",
       "      <td>-1.077875</td>\n",
       "      <td>-0.260900</td>\n",
       "      <td>-0.177046</td>\n",
       "      <td>-0.594063</td>\n",
       "      <td>-0.619652</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.207679</td>\n",
       "      <td>-1.324545</td>\n",
       "      <td>-0.951525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345755</td>\n",
       "      <td>-0.307440</td>\n",
       "      <td>-0.391769</td>\n",
       "      <td>-0.353104</td>\n",
       "      <td>-0.269106</td>\n",
       "      <td>1.041535</td>\n",
       "      <td>0.030754</td>\n",
       "      <td>0.421239</td>\n",
       "      <td>0.420907</td>\n",
       "      <td>0.716244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-1.373808</td>\n",
       "      <td>-1.213565</td>\n",
       "      <td>-0.596040</td>\n",
       "      <td>-0.571164</td>\n",
       "      <td>-0.594063</td>\n",
       "      <td>0.442864</td>\n",
       "      <td>0.739614</td>\n",
       "      <td>-0.712409</td>\n",
       "      <td>0.230288</td>\n",
       "      <td>0.649022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.164256</td>\n",
       "      <td>0.351628</td>\n",
       "      <td>-0.391769</td>\n",
       "      <td>-0.353104</td>\n",
       "      <td>-0.269106</td>\n",
       "      <td>0.710811</td>\n",
       "      <td>-0.110804</td>\n",
       "      <td>-0.144940</td>\n",
       "      <td>2.049116</td>\n",
       "      <td>0.940569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.766739</td>\n",
       "      <td>-0.756686</td>\n",
       "      <td>-0.409451</td>\n",
       "      <td>1.626618</td>\n",
       "      <td>-0.287994</td>\n",
       "      <td>-1.031041</td>\n",
       "      <td>-0.885848</td>\n",
       "      <td>-0.428902</td>\n",
       "      <td>-0.760801</td>\n",
       "      <td>-0.527575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345755</td>\n",
       "      <td>-0.307440</td>\n",
       "      <td>-0.391769</td>\n",
       "      <td>-0.353104</td>\n",
       "      <td>1.837381</td>\n",
       "      <td>0.206458</td>\n",
       "      <td>0.571117</td>\n",
       "      <td>0.740761</td>\n",
       "      <td>-0.437480</td>\n",
       "      <td>0.176217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.573262</td>\n",
       "      <td>0.731325</td>\n",
       "      <td>-0.251961</td>\n",
       "      <td>-0.572992</td>\n",
       "      <td>-0.594063</td>\n",
       "      <td>-0.359812</td>\n",
       "      <td>0.359189</td>\n",
       "      <td>-0.712409</td>\n",
       "      <td>-0.773060</td>\n",
       "      <td>-0.103625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345755</td>\n",
       "      <td>-0.307440</td>\n",
       "      <td>-0.391769</td>\n",
       "      <td>-0.353104</td>\n",
       "      <td>-0.661147</td>\n",
       "      <td>-0.412607</td>\n",
       "      <td>-0.391101</td>\n",
       "      <td>-1.244924</td>\n",
       "      <td>-0.714853</td>\n",
       "      <td>0.077218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.676512</td>\n",
       "      <td>0.531307</td>\n",
       "      <td>-0.157330</td>\n",
       "      <td>1.102763</td>\n",
       "      <td>-0.574200</td>\n",
       "      <td>-0.579614</td>\n",
       "      <td>-0.561745</td>\n",
       "      <td>-0.406324</td>\n",
       "      <td>-0.374984</td>\n",
       "      <td>-0.859282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840491</td>\n",
       "      <td>-0.336036</td>\n",
       "      <td>-0.431918</td>\n",
       "      <td>-0.378765</td>\n",
       "      <td>-0.639774</td>\n",
       "      <td>-0.589746</td>\n",
       "      <td>-0.687158</td>\n",
       "      <td>-0.360927</td>\n",
       "      <td>-0.635707</td>\n",
       "      <td>-0.123924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.960062</td>\n",
       "      <td>-0.788982</td>\n",
       "      <td>-1.135547</td>\n",
       "      <td>-0.541905</td>\n",
       "      <td>-0.232879</td>\n",
       "      <td>-0.257405</td>\n",
       "      <td>-0.391617</td>\n",
       "      <td>0.045742</td>\n",
       "      <td>-0.389976</td>\n",
       "      <td>-0.932278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382524</td>\n",
       "      <td>0.213230</td>\n",
       "      <td>-0.431273</td>\n",
       "      <td>-0.376355</td>\n",
       "      <td>1.209752</td>\n",
       "      <td>-0.517570</td>\n",
       "      <td>-0.094346</td>\n",
       "      <td>-0.362296</td>\n",
       "      <td>-1.215982</td>\n",
       "      <td>0.805708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.918792</td>\n",
       "      <td>-0.395065</td>\n",
       "      <td>-0.948958</td>\n",
       "      <td>-0.377253</td>\n",
       "      <td>-0.585590</td>\n",
       "      <td>-0.636966</td>\n",
       "      <td>-0.900739</td>\n",
       "      <td>-0.690689</td>\n",
       "      <td>-0.422570</td>\n",
       "      <td>0.766905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382524</td>\n",
       "      <td>-0.342700</td>\n",
       "      <td>-0.431273</td>\n",
       "      <td>-0.376355</td>\n",
       "      <td>0.640869</td>\n",
       "      <td>-0.744524</td>\n",
       "      <td>-1.113600</td>\n",
       "      <td>-1.143180</td>\n",
       "      <td>-0.553921</td>\n",
       "      <td>-1.381968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.342357</td>\n",
       "      <td>0.200061</td>\n",
       "      <td>-0.023309</td>\n",
       "      <td>-0.541905</td>\n",
       "      <td>-0.240607</td>\n",
       "      <td>-0.691955</td>\n",
       "      <td>-0.900739</td>\n",
       "      <td>-0.265429</td>\n",
       "      <td>-0.520827</td>\n",
       "      <td>-0.296353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127487</td>\n",
       "      <td>1.089907</td>\n",
       "      <td>-0.431273</td>\n",
       "      <td>-0.376355</td>\n",
       "      <td>-0.668213</td>\n",
       "      <td>0.044210</td>\n",
       "      <td>-0.415439</td>\n",
       "      <td>-0.079747</td>\n",
       "      <td>0.508097</td>\n",
       "      <td>-0.474036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.449418</td>\n",
       "      <td>-1.204940</td>\n",
       "      <td>0.621755</td>\n",
       "      <td>-0.114755</td>\n",
       "      <td>0.353213</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>1.415422</td>\n",
       "      <td>0.131204</td>\n",
       "      <td>-1.024360</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.917795</td>\n",
       "      <td>3.253740</td>\n",
       "      <td>-0.010155</td>\n",
       "      <td>-0.386769</td>\n",
       "      <td>0.108745</td>\n",
       "      <td>-1.378751</td>\n",
       "      <td>-0.992131</td>\n",
       "      <td>-1.659627</td>\n",
       "      <td>-0.943669</td>\n",
       "      <td>-0.352587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-1.169698</td>\n",
       "      <td>-0.788982</td>\n",
       "      <td>-0.651857</td>\n",
       "      <td>-0.918914</td>\n",
       "      <td>-0.240607</td>\n",
       "      <td>0.132067</td>\n",
       "      <td>1.793475</td>\n",
       "      <td>0.201328</td>\n",
       "      <td>-0.109054</td>\n",
       "      <td>-0.932278</td>\n",
       "      <td>...</td>\n",
       "      <td>1.265666</td>\n",
       "      <td>0.247793</td>\n",
       "      <td>-0.431273</td>\n",
       "      <td>-0.376355</td>\n",
       "      <td>-0.668213</td>\n",
       "      <td>-0.517571</td>\n",
       "      <td>-1.375889</td>\n",
       "      <td>-1.067357</td>\n",
       "      <td>0.759088</td>\n",
       "      <td>0.167592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A_malt_all  A_malt_grain  A_malt_bread  A_malt_cara  A_malt_burn  \\\n",
       "6     -0.905714     -1.077875     -0.260900    -0.177046    -0.594063   \n",
       "210   -1.373808     -1.213565     -0.596040    -0.571164    -0.594063   \n",
       "32     0.766739     -0.756686     -0.409451     1.626618    -0.287994   \n",
       "158   -0.573262      0.731325     -0.251961    -0.572992    -0.594063   \n",
       "137    0.676512      0.531307     -0.157330     1.102763    -0.574200   \n",
       "..          ...           ...           ...          ...          ...   \n",
       "172   -0.960062     -0.788982     -1.135547    -0.541905    -0.232879   \n",
       "197   -0.918792     -0.395065     -0.948958    -0.377253    -0.585590   \n",
       "152   -0.342357      0.200061     -0.023309    -0.541905    -0.240607   \n",
       "22    -0.449418     -1.204940      0.621755    -0.114755     0.353213   \n",
       "142   -1.169698     -0.788982     -0.651857    -0.918914    -0.240607   \n",
       "\n",
       "     A_hops_all  A_hops_citrus  A_hops_tropical  A_hops_noble  A_hops_woody  \\\n",
       "6     -0.619652       0.044800         0.207679     -1.324545     -0.951525   \n",
       "210    0.442864       0.739614        -0.712409      0.230288      0.649022   \n",
       "32    -1.031041      -0.885848        -0.428902     -0.760801     -0.527575   \n",
       "158   -0.359812       0.359189        -0.712409     -0.773060     -0.103625   \n",
       "137   -0.579614      -0.561745        -0.406324     -0.374984     -0.859282   \n",
       "..          ...            ...              ...           ...           ...   \n",
       "172   -0.257405      -0.391617         0.045742     -0.389976     -0.932278   \n",
       "197   -0.636966      -0.900739        -0.690689     -0.422570      0.766905   \n",
       "152   -0.691955      -0.900739        -0.265429     -0.520827     -0.296353   \n",
       "22    -0.019925       1.415422         0.131204     -1.024360      0.356300   \n",
       "142    0.132067       1.793475         0.201328     -0.109054     -0.932278   \n",
       "\n",
       "     ...  coriander     clove    lactic    acetic  barnyard   alcohol  \\\n",
       "6    ...  -0.345755 -0.307440 -0.391769 -0.353104 -0.269106  1.041535   \n",
       "210  ...   1.164256  0.351628 -0.391769 -0.353104 -0.269106  0.710811   \n",
       "32   ...  -0.345755 -0.307440 -0.391769 -0.353104  1.837381  0.206458   \n",
       "158  ...  -0.345755 -0.307440 -0.391769 -0.353104 -0.661147 -0.412607   \n",
       "137  ...   0.840491 -0.336036 -0.431918 -0.378765 -0.639774 -0.589746   \n",
       "..   ...        ...       ...       ...       ...       ...       ...   \n",
       "172  ...  -0.382524  0.213230 -0.431273 -0.376355  1.209752 -0.517570   \n",
       "197  ...  -0.382524 -0.342700 -0.431273 -0.376355  0.640869 -0.744524   \n",
       "152  ...   1.127487  1.089907 -0.431273 -0.376355 -0.668213  0.044210   \n",
       "22   ...   1.917795  3.253740 -0.010155 -0.386769  0.108745 -1.378751   \n",
       "142  ...   1.265666  0.247793 -0.431273 -0.376355 -0.668213 -0.517571   \n",
       "\n",
       "     aftertaste      body       co2   overall  \n",
       "6      0.030754  0.421239  0.420907  0.716244  \n",
       "210   -0.110804 -0.144940  2.049116  0.940569  \n",
       "32     0.571117  0.740761 -0.437480  0.176217  \n",
       "158   -0.391101 -1.244924 -0.714853  0.077218  \n",
       "137   -0.687158 -0.360927 -0.635707 -0.123924  \n",
       "..          ...       ...       ...       ...  \n",
       "172   -0.094346 -0.362296 -1.215982  0.805708  \n",
       "197   -1.113600 -1.143180 -0.553921 -1.381968  \n",
       "152   -0.415439 -0.079747  0.508097 -0.474036  \n",
       "22    -0.992131 -1.659627 -0.943669 -0.352587  \n",
       "142   -1.375889 -1.067357  0.759088  0.167592  \n",
       "\n",
       "[175 rows x 50 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0,   1,   2,   3,   7,   8,   9,  11,  12,  13,  15,  16,  17,\n",
       "         18,  19,  20,  22,  23,  24,  25,  26,  27,  28,  30,  33,  34,\n",
       "         35,  36,  38,  39,  41,  43,  44,  45,  46,  47,  48,  49,  50,\n",
       "         51,  52,  53,  54,  55,  57,  59,  60,  61,  62,  63,  64,  65,\n",
       "         67,  69,  70,  71,  73,  74,  75,  76,  78,  80,  81,  82,  84,\n",
       "         85,  86,  87,  88,  89,  91,  92,  93,  94,  95,  96,  97, 101,\n",
       "        102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 129, 130, 131,\n",
       "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146,\n",
       "        147, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
       "        162, 163, 165, 166, 167, 169, 170, 172, 173, 174]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         14,  17,  18,  20,  21,  23,  24,  25,  27,  28,  29,  30,  31,\n",
       "         32,  33,  34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  47,\n",
       "         48,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,  62,  63,\n",
       "         65,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,\n",
       "         79,  80,  81,  82,  83,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "         94,  95,  96,  97,  98,  99, 100, 101, 103, 104, 106, 107, 109,\n",
       "        111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 125, 126,\n",
       "        127, 128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 142,\n",
       "        145, 146, 147, 148, 150, 152, 153, 154, 156, 157, 159, 160, 161,\n",
       "        162, 163, 164, 165, 168, 169, 170, 171, 172, 174]),\n",
       " array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  19,  20,  21,  22,  25,  26,  28,  29,  30,  31,\n",
       "         32,  33,  34,  35,  36,  37,  38,  40,  42,  43,  44,  45,  46,\n",
       "         49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  61,  62,  64,\n",
       "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  79,\n",
       "         80,  81,  83,  84,  85,  86,  87,  88,  90,  91,  92,  93,  94,\n",
       "         98,  99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112,\n",
       "        113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127,\n",
       "        128, 131, 132, 134, 135, 137, 139, 140, 141, 143, 144, 145, 146,\n",
       "        148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162,\n",
       "        164, 165, 166, 167, 168, 169, 170, 171, 173, 174]),\n",
       " array([  0,   1,   4,   5,   6,   7,  10,  11,  12,  13,  14,  15,  16,\n",
       "         17,  18,  19,  21,  22,  23,  24,  25,  26,  27,  29,  31,  32,\n",
       "         33,  34,  35,  36,  37,  39,  40,  41,  42,  43,  44,  46,  47,\n",
       "         48,  49,  50,  52,  53,  55,  56,  57,  58,  59,  60,  61,  62,\n",
       "         63,  64,  65,  66,  67,  68,  69,  71,  72,  73,  77,  78,  79,\n",
       "         80,  82,  83,  84,  85,  88,  89,  90,  95,  96,  97,  98,  99,\n",
       "        100, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115,\n",
       "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
       "        129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158,\n",
       "        160, 163, 164, 165, 166, 167, 168, 171, 172, 173]),\n",
       " array([  0,   2,   3,   4,   5,   6,   8,   9,  10,  13,  14,  15,  16,\n",
       "         17,  18,  19,  20,  21,  22,  23,  24,  26,  27,  28,  29,  30,\n",
       "         31,  32,  36,  37,  38,  39,  40,  41,  42,  44,  45,  46,  47,\n",
       "         48,  49,  51,  54,  56,  57,  58,  59,  60,  61,  63,  64,  65,\n",
       "         66,  68,  70,  71,  72,  74,  75,  76,  77,  78,  79,  81,  82,\n",
       "         83,  84,  85,  86,  87,  89,  90,  91,  92,  93,  94,  95,  96,\n",
       "         97,  98,  99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110,\n",
       "        111, 114, 117, 119, 122, 123, 124, 125, 128, 129, 130, 131, 132,\n",
       "        133, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148,\n",
       "        149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
       "        164, 166, 167, 168, 169, 170, 171, 172, 173, 174])]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "NUM_SAMPLE_TYPES = len(val_X)\n",
    "NUM_SAMPLES_PER_TYPE = len(train_X) // NUM_SAMPLE_TYPES\n",
    "\n",
    "fold_nums = list(range(FOLDS))\n",
    "[num*NUM_SAMPLE_TYPES for num in fold_nums]\n",
    "[(num+1)*NUM_SAMPLE_TYPES for num in fold_nums]\n",
    "\n",
    "val_indices, train_indices = util.get_fold_indices_rand(NUM_SAMPLE_TYPES, NUM_SAMPLES_PER_TYPE, FOLDS)\n",
    "train_indices\n",
    "# print(FOLD_INDICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom PyTorch dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Hyperbolic </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your MLP model\n",
    "class HYP_MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, layer_size, num_hidden_layers, manifold):\n",
    "        super(HYP_MLP, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.fc_in = hnn.HLinear(input_size, layer_size, manifold=manifold)\n",
    "        self.relu = hnn.HReLU(manifold=manifold)\n",
    "        self.hidden_fcs = nn.ModuleList([hnn.HLinear(layer_size, layer_size, manifold=manifold) for _ in range(num_hidden_layers)])\n",
    "        self.fc_out = hnn.HLinear(layer_size, output_size, manifold=manifold)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.relu(x)\n",
    "        for fc in self.hidden_fcs:\n",
    "            x = fc(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define training function\n",
    "def hyp_train_model(model, train_loader, criterion, optimizer, manifold, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tangents = TangentTensor(data=inputs, man_dim=-1, manifold=manifold)\n",
    "        manifold_inputs = manifold.expmap(tangents)\n",
    "\n",
    "        outputs = model(manifold_inputs)\n",
    "\n",
    "        loss = criterion(outputs.tensor, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> EUCLIDEAN </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your MLP model\n",
    "class EUC_MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, layer_size, num_hidden_layers):\n",
    "        super(EUC_MLP, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.fc_in = nn.Linear(input_size, layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_fcs = nn.ModuleList([nn.Linear(layer_size, layer_size) for _ in range(num_hidden_layers)])\n",
    "        self.fc_out = nn.Linear(layer_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.relu(x)\n",
    "        for fc in self.hidden_fcs:\n",
    "            x = fc(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define training function\n",
    "def euc_train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     'subset_frac': [1,1/2,1/3,1/4,1/6,1/8],\n",
    "#     'subset_seed': [0,1,2,3,4],\n",
    "#     'model_type': ['hyp', 'euc'],\n",
    "#     'num_hidden_layers': [1,2,4,8],\n",
    "#     'layer_size': [2,8,16,64,128],\n",
    "#     'lr': [0.01,0.02,0.03,0.04],\n",
    "#     'weight_decay': [0.01,0.02,0.03,0.04],\n",
    "#     'batch_size': [1024],\n",
    "#     'epochs': [20],\n",
    "#     'curvature': [-1]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'model_type': ['hyp', 'euc'],\n",
    "    'num_hidden_layers': [2,8],\n",
    "    'layer_size': [2,16],\n",
    "    'lr': [0.02],\n",
    "    'weight_decay': [0.02],\n",
    "    'batch_size': [1024],\n",
    "    'epochs': [50],\n",
    "    'curvature': [-1]\n",
    "}\n",
    "\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "len(param_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Combination 0 -----\n",
      "('model_type', 'hyp') ('num_hidden_layers', 2) ('layer_size', 2) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[-0.17756096066185756, -0.08925927678246093, -0.06696166516589619, -0.053692415972272256, -0.04330719191339916, -0.048688381861794916, -0.04199735223951184, -0.0370394824236282, -0.030095695041946646, -0.02387490014285576, -0.0189767394187772, -0.015156208745561894, -0.01159026776117189, -0.010412997001075563, -0.009813503015202896, -0.011602631655690976, -0.01460672128393492, -0.0174444456319387, -0.020226786724476753, -0.022902362682031496, -0.025227151586622698, -0.02639083562680944, -0.028549922506266423, -0.03846176615472352, -0.0495752101810949, -0.061472344280247615, -0.0732083177173426, -0.08256037594594567, -0.0879751290612445, -0.09133402465423446, -0.09050529182049494, -0.08944109922328636, -0.08510861372088607, -0.0762701383097848, -0.07040249315142844, -0.07459895295112817, -0.07716922265356674, -0.0794118873524603, -0.080691134927253, -0.08133643161647663, -0.08101295249618401, -0.07881096089659811, -0.08000308172703652, -0.08187544982336337, -0.08238347891045805, -0.08344053717541988, -0.08591696660201187, -0.08783327451890144, -0.08970349131601019, -0.08985601044437996]\n",
      "Fold 1\n",
      "[-0.19157509371527226, -0.0888866551141485, -0.045677851928207724, -0.01925124945557588, -0.01641952931906676, -0.014821485022734837, -0.026581963300620792, -0.02816857061500233, -0.025875090986183347, -0.023921828531230593, -0.022401130388043144, -0.021235480249512717, -0.02046457134866797, -0.020104659476824382, -0.02027202525968419, -0.02079436359616782, -0.021297967645212967, -0.021877023342833812, -0.023900127828452744, -0.023863685042877503, -0.02459200309146592, -0.025427132696165256, -0.026851459709320125, -0.02873432982433677, -0.0303230743038565, -0.03198715449754297, -0.03243943088813839, -0.027902147333301652, -0.022138730275508722, -0.020783561405226747, -0.02134458494410496, -0.02165877763600932, -0.02579073320612446, -0.036552874849614, -0.05319062265786245, -0.07190104842084022, -0.07368589087658028, -0.06916796992810315, -0.068594122548856, -0.06540874063996305, -0.078410141510044, -0.07788182531243537, -0.08318600979453272, -0.09089951687413556, -0.10077623630984744, -0.17324293189636664, -0.16702476312820957, -0.145709980167694, -0.16216552905261739, -0.1379729731288124]\n",
      "Fold 2\n",
      "[-0.18104893469652072, -0.08868726325926657, -0.04793042453306695, -0.036150479723600526, -0.03089135627769779, -0.02619709342781107, -0.031239985731310593, -0.040218310366526344, -0.03740706492184098, -0.035430184155247124, -0.03435067908591516, -0.033954403707313396, -0.033775789505319675, -0.03416785993539939, -0.03504563663412341, -0.03615149059364886, -0.03801391455772474, -0.04079374796096258, -0.044471894635766285, -0.049127866168787726, -0.05482169378155022, -0.05987100231367681, -0.06617181351527424, -0.07391774968266351, -0.08429707505347284, -0.09721486838542615, -0.11274505005243651, -0.1255815315239408, -0.13436368840956425, -0.1395111012771344, -0.14362799185726516, -0.1393288096045302, -0.13277485621624696, -0.12373445474697187, -0.11338620006755273, -0.10600340370837924, -0.10388048535615746, -0.10309755391142317, -0.10358612787259447, -0.1040990814734355, -0.10346942543370607, -0.10197449900691713, -0.10037258846786168, -0.10018597640851623, -0.1018917075220871, -0.10636191971139519, -0.11099236958793823, -0.11134268840016759, -0.1112336401453804, -0.10841744995605818]\n",
      "Fold 3\n",
      "[-0.1837126527875348, -0.0869685697861653, -0.052878386898892016, -0.03221956784536428, -0.026543640799279844, -0.020857639653211857, -0.022751519287159683, -0.02916308278902391, -0.027111690683730982, -0.023904116247691398, -0.020859894163762105, -0.01826922421706656, -0.015489577809758348, -0.012754009675907119, -0.010244006659771099, -0.00804755378468136, -0.006406946487708343, -0.004435017675469277, -0.0019970957076240747, 0.0010280551944046312, 0.004080752619700423, 0.0073639194226093885, 0.010469358808538831, 0.01283956410374143, 0.013676050755815905, 0.013748973730489111, 0.01408279143122837, 0.01508996443727606, 0.015925946177304806, 0.016671467840072896, 0.016840786566704513, 0.015234409479442879, 0.01045723213645311, 0.007419294551334943, 0.008815447600126425, 0.009161133255713771, -0.002338373822881712, -0.018863824747123115, -0.01988377754707704, 0.00477907020720425, 0.03633941432813992, 0.05179470653043339, 0.06379384457477255, 0.0655793615848238, 0.06467256547094058, 0.0609168496577841, 0.06468418416388699, 0.07407779938605219, 0.07378577382964269, 0.07299314484050878]\n",
      "Fold 4\n",
      "[-0.1828229374997572, -0.08691609133759393, -0.05019622047773309, -0.02871176718704116, -0.024783479842543032, -0.03792560862439487, -0.037409178988437874, -0.035346315090450275, -0.03432682611420712, -0.03412763954436304, -0.034056595565706616, -0.03426196797363157, -0.035158170514779874, -0.036735863728723395, -0.03925375756804095, -0.04230011055326144, -0.04640525054983757, -0.051258191204492265, -0.05619193487715446, -0.06096642311519895, -0.06610630177593779, -0.06983403394386323, -0.07487935301398241, -0.08162482983078267, -0.08633319764834924, -0.09184882523569726, -0.09673396846951077, -0.1022986585869956, -0.10311473441215946, -0.09317809030394186, -0.06557415257472532, -0.055832326586381376, -0.055865015527980066, -0.06233625162383771, -0.06377749360195217, -0.06287949595782472, -0.07403459350762898, -0.08719570473583982, -0.09751296110348684, -0.10575052461754031, -0.10439342293399378, -0.10849618291548979, -0.10972396099702753, -0.11040662860408834, -0.1310902598288517, -0.14476146414209312, -0.11846065034158326, -0.11615138967188865, -0.11832024840025479, -0.13025259492825114]\n",
      "----- Combination 1 -----\n",
      "('model_type', 'hyp') ('num_hidden_layers', 2) ('layer_size', 16) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[0.000740894687446203, 0.012931117493009014, 0.03797609501896182, 0.0510671485919425, 0.04937538923070628, 0.04420208499277867, 0.0437421657803686, 0.034054876331780615, 0.01572507328477779, -0.0070306916831675, -0.03239310569589793, -0.06483472516636968, -0.09625928372136339, -0.12562074596069173, -0.14720849458121799, -0.15436335541584656, -0.16858166954080933, -0.1920370958780857, -0.22703704037268158, -0.25609190280065675, -0.27730114873244927, -0.29439899969379946, -0.2983721373062702, -0.2864043474139937, -0.273963424501924, -0.2675934704492702, -0.25845097287275953, -0.25027974939762676, -0.24820153859472716, -0.2458555200651893, -0.24113662100654598, -0.2446968592500196, -0.24682884275414385, -0.2474926349806792, -0.25318420538011854, -0.25310510319186763, -0.25909403778353934, -0.26468035395654166, -0.2673217442735554, -0.2750924991479242, -0.27775720332333953, -0.28429040446549125, -0.28750771282759136, -0.29002880731351155, -0.29505660247310317, -0.29670170415339814, -0.3073724072609383, -0.30002200282759683, -0.326475792432962, -0.29522529810702824]\n",
      "Fold 1\n",
      "[0.0738247813475732, 0.12112819799352847, 0.11184759147314027, 0.10974097895470547, 0.10608791640822868, 0.0855227805037787, 0.05567481934369656, 0.018624784113415838, -0.008223143120567267, -0.024202114061485647, -0.052955702218312695, -0.10115099798388627, -0.1511900260133474, -0.17193981630813426, -0.19088796721583878, -0.2131346023141667, -0.22017162588108086, -0.21406156949959598, -0.21237132494531785, -0.21670675012157714, -0.21006478152725805, -0.21633322240296082, -0.22731051470444252, -0.2275966321341647, -0.23629931552650785, -0.2433576766888914, -0.2331727840641591, -0.22737699372870668, -0.23419913783289026, -0.2263501772386347, -0.23150584644996086, -0.23806883368094467, -0.242561243124789, -0.2618077286536262, -0.265519494283067, -0.28585521192343855, -0.2874281362613462, -0.304854361725756, -0.28910851942687654, -0.3233170196166515, -0.2464715827401096, -0.3736216979833109, -0.2629585472139859, -0.22851051185863214, -0.32555319756674095, -0.2741658478648257, -0.20439856341748586, -0.26580691236241316, -0.2983711299439198, -0.23160495093501132]\n",
      "Fold 2\n",
      "[0.03177253640791189, 0.0735639214792112, 0.04646253306340764, 0.0724026907033235, 0.08962574957340386, 0.09310389725752888, 0.09496893335223167, 0.09024597812028134, 0.07658874950624506, 0.056536066229958104, 0.042327373227360465, 0.02141981509756752, 0.0014982192144702422, -0.009156713022468121, -0.0249151218371626, -0.031016132451606504, -0.02631161741227772, -0.032868997339424944, -0.04166410794400255, -0.050085034725998456, -0.04071617499825697, -0.026358929747054116, -0.029757516917550575, -0.0372762793199255, -0.028119374276404985, -0.022937718110838112, -0.03330534886179226, -0.04050008453876508, -0.03286365700543614, -0.02798618769837513, -0.030280398058370572, -0.024441181880644924, -0.016297458685290866, -0.022905478610839136, -0.031954779962016566, -0.030427686814350263, -0.033878028831556994, -0.04338282756806233, -0.04045906724470427, -0.044592921750510994, -0.05046784956132511, -0.0477029406703573, -0.05502177448704959, -0.057138450720040534, -0.05347962151710073, -0.05885297821806135, -0.0510208579485929, -0.05826759475743715, -0.05753466191804901, -0.06266366532110945]\n",
      "Fold 3\n",
      "[0.09246778341098627, 0.08204681919388535, 0.10898077440620013, 0.11628845309403435, 0.1105814473615071, 0.09425928850725585, 0.06130497838591664, 0.05051967801967461, 0.05289927288882634, 0.04682083919352931, 0.03115538515846006, 0.018032422485570132, 0.017530922796487824, -0.005454681449507781, -0.06812071641378359, -0.1262578587695944, -0.15584494024322226, -0.18384499185385628, -0.1799560661714079, -0.1680334915257118, -0.20451482530728615, -0.20365581052867854, -0.22948731650658227, -0.23251749273611466, -0.20704004110879493, -0.2054082176081251, -0.20951101302662645, -0.19354848911723854, -0.19808544997062283, -0.21671648521223008, -0.2164042977141727, -0.21607996509617022, -0.22246281127391043, -0.213684771961397, -0.20326310545448378, -0.2105104843223582, -0.21652327066379384, -0.21223159711300976, -0.22176419737780484, -0.23073181054989678, -0.22196090208743913, -0.22303544618466442, -0.22514735106523065, -0.21268400427735834, -0.2180937440271684, -0.2277968087822717, -0.22026607760590222, -0.22782289183972604, -0.2273038873368376, -0.2192566619759253]\n",
      "Fold 4\n",
      "[0.0897319960232833, 0.0934872799617501, 0.11644675137618665, 0.1173095454408758, 0.09830843880739348, 0.07323049718145969, 0.04434202145187893, 0.019533928150791358, -0.005316265485651339, -0.04299030156655159, -0.08332753719006236, -0.12391752547856294, -0.16011155787300724, -0.17853272518577867, -0.2011912907173894, -0.21719809594896256, -0.21727466736602397, -0.20724447208223395, -0.1949791998707857, -0.1912356142418623, -0.18584589602133095, -0.18711872671616536, -0.1863277107130059, -0.17784827016853888, -0.1714015774299531, -0.16661049679892548, -0.16914153054123626, -0.17782916194235, -0.18120791808958336, -0.18585869582639303, -0.18404704498184987, -0.19639114396823065, -0.18352119319520788, -0.1900473133767122, -0.17248769645629403, -0.16097598757453757, -0.1717127147911064, -0.1610233355410342, -0.16326059591778663, -0.1790277313989459, -0.16710620567274548, -0.18519662423599925, -0.19765137615591843, -0.18804529891271105, -0.20352332224250658, -0.19569815684356628, -0.1921274290691406, -0.21323530667894586, -0.19855696670172351, -0.21957051153289298]\n",
      "----- Combination 2 -----\n",
      "('model_type', 'hyp') ('num_hidden_layers', 8) ('layer_size', 2) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[-0.0986034743258728, -0.030521570719326485, -0.00461058039158857, -0.004276252200205333, -0.00798598795172012, -0.008252454166200573, -0.008031915188727812, -0.007498871381899752, -0.006960083914786974, -0.006490276470294987, -0.006051716838052723, -0.00566355494192905, -0.0053226686946448165, -0.005017029567409015, -0.004741265045602017, -0.004489638305302135, -0.0042554109611729896, -0.004034626718328216, -0.0038179642972002714, -0.0036096937556029385, -0.003410729525327616, -0.0031819565827493346, -0.0028564718331713923, -0.0025178944222306043, -0.002166773648444087, -0.0017737965264248423, -0.0013502620500513984, -0.0009167702353127805, -0.0005115495467249431, -7.694704391414398e-05, 0.00041495021443116453, 0.0009677312549246642, 0.001611527172436844, 0.00235255794535294, 0.0032316853230226483, 0.004269674881393293, 0.00547732149122615, 0.006959753852852857, 0.008769153835191945, 0.010971377029826868, 0.013517821404984032, 0.01604903801248103, 0.018014449852156944, 0.019550263592013062, 0.0179679063961401, 0.01636324863819205, 0.017043696011674436, 0.03501380093467055, 0.04941945840826889, 0.05428587472597102]\n",
      "Fold 1\n",
      "[-0.10222406085839286, -0.03330844590220772, -0.0011583290592991347, 0.0011173057634201733, -0.003272117370389571, -0.005268076891553841, -0.00540072169848127, -0.005358481129571269, -0.00525554996727573, -0.005409963703300491, -0.005305745441066545, -0.00515744607962243, -0.004992249257968595, -0.004743352871249051, -0.004436543254854541, -0.004055412557372184, -0.0036562045613592886, -0.0032520316189348364, -0.0028404293278985193, -0.0023286125117196743, -0.001663459585076854, -0.0008372664020808163, 3.5883492505162096e-06, 0.0008777217620882238, 0.0018144383295813915, 0.0027346290649133964, 0.0036628195466018587, 0.0045697961113096985, 0.005578524837586807, 0.006794086376455288, 0.008090105078428889, 0.009651651414319673, 0.011595605878994553, 0.013617206687139505, 0.015702170229741075, 0.01831347615909329, 0.02086178279407047, 0.02364368597835964, 0.026333464140162466, 0.029214740595952637, 0.0332363885655228, 0.036719245196930816, 0.04055060683498868, 0.04685839978278361, 0.048638351329807206, 0.0479182059225024, 0.046527621273153574, 0.04507519837389673, 0.043080692852113356, 0.03997571125935384]\n",
      "Fold 2\n",
      "[-0.1032444032656823, -0.02722229871765225, -0.00015662754769296683, -0.007295665909586413, -0.013689507270088885, -0.013753040855638332, -0.013208457773306481, -0.01246663878801435, -0.011687330242985183, -0.01090121524749077, -0.010596705207441381, -0.010249807289266055, -0.009922825429332205, -0.009619779996604017, -0.009336942848456209, -0.009083037103104763, -0.008958930873992799, -0.008908908750365319, -0.00888975635546041, -0.008863355103055026, -0.00886020541816146, -0.008805924778942709, -0.00865212393881265, -0.008458467942358716, -0.008305071521211183, -0.008209348694276475, -0.008208373953722203, -0.008234133717514025, -0.008333734862794762, -0.008434473440316115, -0.008549260541422576, -0.008707086602489422, -0.008918426487173337, -0.008909979136563662, -0.009351831474769368, -0.01057058707565095, -0.01303643571572577, -0.017624157961710907, -0.026063755602964145, -0.037798942987262496, -0.051163547339105, -0.05848322808561557, -0.06020912187999339, -0.05772360180246161, -0.05386829629730472, -0.049543843590115655, -0.0498034687520017, -0.055650773366041406, -0.05959769766821266, -0.05897861330080989]\n",
      "Fold 3\n",
      "[-0.10440969330622751, -0.02977615778449949, 0.0006419695787100999, -0.0028092252778191273, -0.007878883510002987, -0.008234836068429896, -0.007669320371676003, -0.007156260860554431, -0.0068326941186513945, -0.006719926436738799, -0.006391993474010427, -0.005964726716823465, -0.0054867016795370205, -0.0050276614495128324, -0.004551707716838438, -0.004007793478368216, -0.003440199024598023, -0.0028286422547523227, -0.002171619913219791, -0.0014743077156027518, -0.0007616467805957594, 5.173076635278662e-06, 0.0005436321156618851, 0.0011106297265065512, 0.0016931392981145432, 0.002346693769406216, 0.003023588746043915, 0.0036057413374049885, 0.004310693864632786, 0.005158028315186969, 0.006172666025297313, 0.00738045432904022, 0.00879213227451403, 0.010459715766321653, 0.012348764386979849, 0.014767464624490523, 0.017064954205081362, 0.0184803143862049, 0.018878988418293163, 0.016921615490096853, 0.015468221422043182, 0.01691811355433981, 0.018043276474063563, 0.025590328959770647, 0.03426086307762066, 0.04031619581760393, 0.04344252874967247, 0.04501098660068703, 0.0464232756310089, 0.04706135431390113]\n",
      "Fold 4\n",
      "[-0.1017651911166555, -0.02850612898859417, 0.0012845269606137633, -0.006208721497813263, -0.00976432384248005, -0.009524637404950242, -0.00923897926572459, -0.00915940513016289, -0.009166467350943952, -0.009016632089178467, -0.008770070419220177, -0.008425611967858071, -0.008084164413838968, -0.0077823196138107065, -0.0074792421876563875, -0.007093498842027479, -0.006675468956219621, -0.006207012663540956, -0.005689067087801147, -0.005184068802728703, -0.004574832491713643, -0.0038694943279362626, -0.0034835825303749512, -0.003123070862101285, -0.0028177379792919677, -0.0025654322011039454, -0.0024820561311160727, -0.0026811307195133693, -0.003369974234856743, -0.004708320982812264, -0.007197742929700546, -0.011463124655267443, -0.01870999921535277, -0.03052391244898911, -0.04324756633866178, -0.050081553788146715, -0.045980093728724025, -0.03258887643783148, -0.013639446830157054, 0.0016434052557969814, 0.008546372954304826, 0.009508307968365881, 0.006820736340123923, -0.003296252059004523, -0.01663782022763538, -0.032336296429783085, -0.044101960448255095, -0.048452719604762384, -0.05176354702676078, -0.05554625221534293]\n",
      "----- Combination 3 -----\n",
      "('model_type', 'hyp') ('num_hidden_layers', 8) ('layer_size', 16) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[0.061117938926476545, 0.03721056948160428, 0.09481862414419417, 0.12223140087356132, 0.1274682606494183, 0.12907990696969585, 0.10799576041381453, 0.04501454923763826, -0.031535019835208455, -0.10795179113318065, -0.10030136697511871, -0.08084351081527763, -0.06825971786571294, -0.07395907255737288, -0.10553043099576476, -0.13799264119117183, -0.1636255151718562, -0.17835762287505363, -0.19463589975017048, -0.2004386873786368, -0.22506390904963847, -0.19066204116891905, -0.1686798448409348, -0.1676922027556147, -0.16419229752712416, -0.17431819913716695, -0.17615960327957536, -0.18487154019746166, -0.1998015532685442, -0.20377561061858285, -0.21575439100714355, -0.2175948800791887, -0.23597148501116694, -0.24586130090062275, -0.24702228212070199, -0.2488647064042584, -0.2583948892424457, -0.268812133956297, -0.27866444157333015, -0.28345737430065365, -0.28200639527093796, -0.2838350252380828, -0.2866829473265502, -0.2818608429266216, -0.2747975791903028, -0.27182579423050046, -0.27172703605656645, -0.27917082561353457, -0.2867554089958402, -0.29045229827159336]\n",
      "Fold 1\n",
      "[0.08975494578701015, 0.05576228116800541, 0.15787020592398304, 0.09741502074872521, 0.10461575845068438, 0.12728849202743586, 0.13777887714704196, 0.13880271875578976, 0.13893224109358426, 0.13849025911681212, 0.12891842914291662, 0.08922479492611646, 0.027539175491669288, -0.04000292077542378, -0.12468599524608592, -0.1930083887345666, -0.20596955501462944, -0.19650871361794175, -0.1676392463500509, -0.14506991102997513, -0.12477329173254437, -0.12881488927397267, -0.14279561899652427, -0.1581114007410489, -0.16137251860630109, -0.15164384649508933, -0.13491646634039767, -0.1203925406711408, -0.11546089216277067, -0.12422543293119159, -0.13324547665828024, -0.1400244098413863, -0.14181200388204696, -0.14132233708234243, -0.13754170495292595, -0.14210784491353756, -0.1618622131539187, -0.1861132042126976, -0.20327997175078516, -0.20685795908854332, -0.19907295942364822, -0.19406019092718485, -0.20041407542184642, -0.21115208007361574, -0.2240794923058098, -0.23114475024702874, -0.24147608503919504, -0.19547642204418758, -0.19806201689243053, -0.24592260051079173]\n",
      "Fold 2\n",
      "[-0.054480774349050076, 0.07896515173997054, 0.0655845108029105, 0.11107657223551715, 0.13458546208487288, 0.14060306408731282, 0.14194576604705378, 0.13794333830509198, 0.11310602633879252, 0.05277880938903179, 0.02815203857826254, 0.01905751530687294, 0.030382546754422868, 0.06196623090975317, 0.09018430238536967, 0.09488273085121435, 0.10407096035630248, 0.09732140811284373, 0.08882507467387035, 0.10433336996769194, 0.142977935516585, 0.15522701778819803, 0.13098102851676208, 0.07425702121983835, 0.07528527645820182, 0.08518989959102463, 0.05444157757984669, 0.008328992699342841, -0.006263759837050076, -0.013018278251733628, -0.02924226975711952, -0.040738677716183114, -0.053152892184985534, -0.0714542905421518, -0.06450770155300933, -0.05305263977367414, -0.06668982517944988, -0.079354054729176, -0.06786443299720224, -0.07592307272004506, -0.10170101040365842, -0.10457487853235459, -0.10113113061473333, -0.10171965687789597, -0.10008442637346793, -0.10013679272143405, -0.10375728430535891, -0.10595206775733956, -0.11218614661684678, -0.1205825957110267]\n",
      "Fold 3\n",
      "[0.12624468864337546, 0.08276406150502913, 0.15383708084574454, 0.16100220109621155, 0.15379120279245584, 0.12032542110574895, 0.08123093258951786, 0.06625004878125162, 0.0459907975709708, 0.010671150462127077, -0.027799695753101705, -0.011034535250673772, -0.011011714224139268, -0.027261076111871896, -0.04417984779295914, -0.030469257887322243, -0.06179580605553259, -0.12480123306460511, -0.11177796145090868, -0.11648507974954825, -0.07501522362968549, -0.06186515281567195, -0.057494357441916444, -0.062453980331689474, -0.1085630861617295, -0.07712490594722432, -0.0854210643597797, -0.09798143682603833, -0.10680512328054514, -0.13144978075378777, -0.1425107792175333, -0.14711450484239075, -0.1649967266149004, -0.15418928049567637, -0.15521558203997476, -0.12084724340117203, -0.11457223647769887, -0.13261284815778063, -0.12526497102110268, -0.10491961546860584, -0.10670233526348372, -0.12569927607641906, -0.11727689938910446, -0.1260704892272344, -0.138870697458936, -0.11223649662881963, -0.12222315568227171, -0.1368761730362713, -0.1334000231544865, -0.16148044139812057]\n",
      "Fold 4\n",
      "[0.11960122357217928, 0.08709528159663615, 0.15428263823913557, 0.16851880255143514, 0.18121128388658125, 0.1886885261539042, 0.17646776607540127, 0.14808883356472946, 0.09917447091504161, 0.05303717580005474, 0.0206322811717784, -0.013031096332340564, -0.04922942814610609, -0.07614469108472499, -0.043689012582506015, -0.0741587590192323, -0.01456261919639168, -0.0672171967419235, -0.013160385527343221, 0.03872947232138946, 0.024372301215658032, 0.003816186164288693, -0.03872535139954869, -0.0479955091933526, -0.03184924314632398, -0.035106832758965645, -0.03858816994588876, -0.05065852373917079, -0.0563094479932984, -0.05434189740221407, -0.06488724612838004, -0.08172871089268985, -0.10702764431445111, -0.11228364027475357, -0.10090251511609094, -0.10069073760926206, -0.10933998025885727, -0.10210367918996743, -0.08260881409585163, -0.07669237321879074, -0.08160971688008578, -0.07922001312565907, -0.08060292465534435, -0.09323111077183244, -0.10177685295065952, -0.09875478095154233, -0.10162445767720629, -0.10957522137735709, -0.11553476816622554, -0.12821378279184947]\n",
      "----- Combination 4 -----\n",
      "('model_type', 'euc') ('num_hidden_layers', 2) ('layer_size', 2) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[-0.18026478261246548, -0.09826219765507815, -0.04275473297581156, -0.0024571205674517316, 0.028574367420154734, 0.053384765371709664, 0.07364048737630935, 0.09241134484106128, 0.10904362175865101, 0.12286434788879486, 0.1321809842155428, 0.13725461756796842, 0.13872421979501726, 0.13741125846796287, 0.13549531345774657, 0.13389962830835955, 0.13242561160798294, 0.13054841971984343, 0.1286906051793686, 0.12500726914341653, 0.12010237474959584, 0.11425587195435871, 0.1064997148715191, 0.09601416356394021, 0.078326523499616, 0.05509945675189831, 0.032611028081336535, 0.017600257655899454, 0.010615757340970422, 0.006003253577075429, -0.008004906613001683, -0.021972208032149387, -0.03299879896341551, -0.04321619369282437, -0.044484786082740646, -0.03917115878575683, -0.03417437907424126, -0.051310323545897374, -0.06896796139160855, -0.08314621867464345, -0.08129595826377933, -0.08892377994429856, -0.12813501688452233, -0.15158620638205944, -0.1578170505420473, -0.1707256380822948, -0.1872572129247907, -0.195487057114603, -0.2004496374266167, -0.18664133395443794]\n",
      "Fold 1\n",
      "[-0.1803153663645929, -0.096844587673933, -0.04392185815797234, -0.009388316397379803, 0.01836649123981915, 0.04280082062793922, 0.06304392707999984, 0.07934486837892907, 0.09157374009344466, 0.10014740370484077, 0.10314128117878596, 0.10272937553108685, 0.1009360654474446, 0.09960276869682627, 0.0996144972940084, 0.09908918493623198, 0.09997438349794718, 0.10043666417727992, 0.10050194202443397, 0.09991011076470846, 0.09950098400355334, 0.09786365108514827, 0.09530570896759494, 0.09275989065973289, 0.08951153024385028, 0.08421264454572852, 0.07654711289984217, 0.06745476008053142, 0.05732317931952258, 0.04890072102987719, 0.0432209632877657, 0.03983776152154328, 0.03799913555456824, 0.03603894652844819, 0.033057425801158224, 0.028696417442593214, 0.025540854927776913, 0.022592413436657077, 0.022496399082247542, 0.025067863681027314, 0.027130043007724702, 0.030011637506107247, 0.03214188621719849, 0.03634390747742933, 0.042834948473040146, 0.0515870918072896, 0.05446491240881002, 0.05878646742006466, 0.07815273557279523, 0.09659004294438178]\n",
      "Fold 2\n",
      "[-0.17774676098197206, -0.09466939558993959, -0.03565493194908109, 0.005245807931846813, 0.03594679814658075, 0.06402989256023328, 0.08784874586630675, 0.10652931457416281, 0.11929662248282213, 0.12705688407761373, 0.13213710473804852, 0.13545542724459125, 0.14081786987328215, 0.14699378957306652, 0.15326757315544537, 0.15879851999501848, 0.16314829928302788, 0.16649354318359555, 0.1685121669080396, 0.1693953935106821, 0.16908338939300305, 0.1692702986732274, 0.16798058676069927, 0.1714794171391767, 0.17820270122310056, 0.1827191822542663, 0.1870483654850631, 0.19084138290492525, 0.1971903628449282, 0.20706352691734708, 0.21516446621791752, 0.22065535364928335, 0.22038582266475482, 0.21462761596773372, 0.215029504491427, 0.2149125327285003, 0.21515110240494995, 0.21468125491466583, 0.21681816363014472, 0.21702611603618582, 0.22189158844540613, 0.22831523892372196, 0.23168072239892634, 0.22468239407656654, 0.21414736299327297, 0.20747497121740466, 0.19738339648161607, 0.1893093179081069, 0.18151364286374172, 0.17939004796855573]\n",
      "Fold 3\n",
      "[-0.18989313636953709, -0.09607090309291766, -0.036502305469779506, 0.0032002087329554563, 0.029922917661107218, 0.05347122369008628, 0.07313605314143345, 0.09035925664308342, 0.10547748796735201, 0.11870531214734015, 0.12847448262164773, 0.13441155151654438, 0.13832710320488295, 0.14088550906436204, 0.14270973384067043, 0.14457736727573, 0.14646358306072849, 0.1476941450286705, 0.1480943865543367, 0.1460536749372171, 0.14022408256477792, 0.12999522349505765, 0.11514195765679602, 0.09674325821301322, 0.07722980303799432, 0.05789131924181812, 0.03680210390512029, 0.009401810314997316, -0.016905483087950035, -0.038927878073634625, -0.06563820599781223, -0.0980259202542888, -0.11145917654269533, -0.11603313203420007, -0.12666041766652336, -0.13114400301697682, -0.1277141827350945, -0.12479198598881358, -0.11673391535631761, -0.11202020172354366, -0.11869728490279208, -0.12933287169841257, -0.13587153826456655, -0.16003068826315614, -0.17414481039696716, -0.1860218754891385, -0.19226507240869606, -0.19835320540373957, -0.19757730497131232, -0.20647093486968626]\n",
      "Fold 4\n",
      "[-0.16996633816876616, -0.09277037946348643, -0.04028423376573853, -0.0017882669029325449, 0.030836057686690732, 0.055962646719196485, 0.07795118855413818, 0.09652850343585118, 0.11115470496397406, 0.11964940567229532, 0.12291783546870072, 0.12265857014464876, 0.12195037575148293, 0.12332941729533609, 0.12705987555680198, 0.1326772393583362, 0.13876557576765636, 0.14447916661776872, 0.14900915831109163, 0.15107284330057247, 0.1506329158571984, 0.1477006412851506, 0.1432999314071578, 0.13755505365980547, 0.1309246885613694, 0.12396016972050428, 0.1174440598745422, 0.11183996870292223, 0.10642655001619705, 0.10130727484143509, 0.09483098292210457, 0.0844000560107705, 0.07195096308540339, 0.06235130723733595, 0.05798502545383699, 0.05796872341453063, 0.05672756666341494, 0.056156329620196566, 0.05475545318619013, 0.05403862532455195, 0.05497924190015058, 0.0564329292896083, 0.05761397360006082, 0.058209136407940565, 0.056736856218822185, 0.05419295052918349, 0.060099886673896874, 0.06614662542174266, 0.0658342917162088, 0.06843188654489296]\n",
      "----- Combination 5 -----\n",
      "('model_type', 'euc') ('num_hidden_layers', 2) ('layer_size', 16) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[0.03151175336410206, 0.06849999295000153, 0.11441281813313031, 0.1362587899896872, 0.04118935385103284, -0.011280100638032975, 0.042026410334767506, 0.006405133432331511, 0.030159698372143273, -0.13072596625480504, -0.15095383108449467, -0.010892606609462119, 0.024466345774379894, 0.012705061795078021, -0.019414011616804894, -0.05150206360674403, -0.05599677741755382, -0.041201136403343996, -0.03069251094923664, -0.03420251933044871, -0.04320952467588812, -0.058155299038342045, -0.04886365990899444, -0.026083478889715517, -0.02467591689007209, -0.04434250058040212, -0.06518178976671973, -0.04806239260522238, -0.0005752591896110992, 0.026505724143443432, 0.029254752452614996, 0.030847149024711418, 0.0509067878804319, 0.05318966689074012, 0.029974929003999007, 0.024346089356671596, 0.06954728888595041, 0.02635097046122936, 0.05354666133996733, 0.050912440396386316, -0.001737455572145663, 0.04383914558839297, 0.031061423525057585, 0.0012101955957296573, 0.02866646318831545, 0.0368410919635741, 0.0231456516324684, 0.013024686635665361, 0.06095398004950048, 0.006640313028299594]\n",
      "Fold 1\n",
      "[0.037181330308223126, 0.09097949387501991, 0.14834566504521984, 0.2014225041207991, 0.13836076394068075, 0.024495598437464072, -0.010780905822173281, -0.011530012607972484, 0.04021754447228787, 0.01686776838117854, -0.06223182374264846, -0.04738813099663419, -0.05327883442118364, -0.09698224639468922, -0.07715416156705412, -0.04498794732864697, -0.062110763330346375, -0.09323371482292364, -0.07020577563251185, -0.03990772035204082, -0.024957037532865378, -0.035207951324261355, -0.03026375218932964, -0.03222728509111139, -0.0604534447844729, -0.07862423948353126, -0.07039233231125253, -0.06876047384110517, -0.06812782830546849, -0.0685703202229897, -0.012905845518628833, -0.04921155400788502, -0.028942360858501326, -0.024525795156030483, -0.05517835563816442, -0.012567531528338227, -0.007013416712122522, -0.116023273941122, -0.030128953914369427, -0.005591047564459384, 0.020588989650294987, 0.027465683229421334, -0.02507564198095369, -0.04200547885885819, -0.020352043749347626, -0.018532881151195113, -0.029878397534717216, -0.02090693233620078, 0.004706064402110632, 0.00013226913892905312]\n",
      "Fold 2\n",
      "[0.03795333181450855, 0.08630924044337251, 0.10536003958808038, 0.11625702927202008, 0.06733910296266787, 0.0889978115081641, 0.11551356840455318, 0.10463298077884764, 0.1409929358900439, 0.15637935466301423, 0.13468307967468485, 0.09932937970167643, 0.07071541334606879, 0.17402700510822944, 0.18951781137773138, 0.2064482229240372, 0.21773350399389524, 0.17034383204907322, 0.1331210347818077, 0.15145272847652202, 0.1446607848145519, 0.13477782507117908, 0.1689569585631715, 0.17905785121998852, 0.1505034533120322, 0.16193374700491536, 0.17797197989679014, 0.16447454520439764, 0.18715151697090926, 0.16198053380288324, 0.18745762002626498, 0.13621337562059255, 0.17949467913887107, 0.049822411359751295, 0.16864034589020338, 0.16298814274363693, 0.05713576903334616, 0.11999060119734395, 0.14662385404963985, 0.11838195134445106, 0.06177783030085682, 0.08112765607069605, 0.15487770672435108, 0.1749672370766273, 0.16687209701871053, 0.16256195445684252, 0.17775303292333677, 0.17356566728816725, 0.1759971769279992, 0.17456857052760444]\n",
      "Fold 3\n",
      "[0.03958408771370803, 0.09856147752302569, 0.14670566506519078, 0.10674304821355962, 0.10581760220531877, 0.07552076122287343, 0.07805512090247402, 0.035680998270167685, 0.0026144063121881223, -0.1659405859974068, -0.08246270275129786, -0.07275153825836767, -0.09223287009605174, -0.09740556231616004, -0.05090437773054424, -0.002905229962097966, 0.007680376956597068, -0.02695106572764039, -0.09062924427663033, -0.11527339904974232, -0.07878543875398081, -0.047019676187174175, -0.03490500525527973, -0.026330253932237424, -0.0024463858748731138, 0.030012268708681344, 0.047473314596295, 0.04355065645603595, 0.0255604594224067, 0.02999933908249608, 0.029324574020356264, -0.006923308281446605, -0.012473668391751014, 0.01276032006852823, 0.014918912788485006, -0.005587678387650286, 0.010888245244364936, 0.02450526227018368, -0.005035563810467325, 0.058554205345549115, -0.03641831274096541, 0.0726107044308949, -0.0737094047438962, 0.02361877567671522, -0.03822720053678852, 0.03680102527272178, -0.02174085880474097, -0.10139674612942629, -0.020998681211609638, -0.018048281239348762]\n",
      "Fold 4\n",
      "[0.029127781629749716, 0.09209742206984761, 0.15123508251000606, 0.13498693737217204, 0.11227985856220113, 0.0753160239853875, 0.03392916032183424, 0.04980628676595933, 0.036315713696261964, -0.07028068446815827, -0.15226758632485948, -0.11584823294392055, -0.0950554224843374, -0.12343595688486686, -0.15185537557376172, -0.13766251903867888, -0.11544289950203401, -0.12624840999967435, -0.16408471986774908, -0.1922501968042445, -0.19723889710921116, -0.19843151094928246, -0.20005711138303517, -0.190495621758193, -0.17976903419074342, -0.19489967446484568, -0.24166617557307668, -0.23438739942551168, -0.21745905649203023, -0.23883501692862374, -0.20834896243005008, -0.28291835697587997, -0.2248943742506606, -0.1645195931018133, -0.2002198916891691, -0.16256011242876411, -0.18839219822843245, -0.22688188146529908, -0.2352152956041762, -0.22530680050515528, -0.2193359698076809, -0.2129179183425376, -0.19252039016559186, -0.18408378397810843, -0.1873276820802261, -0.16765729755512226, -0.15705173197988076, -0.16274894603585244, -0.1580929587770894, -0.14720384775072604]\n",
      "----- Combination 6 -----\n",
      "('model_type', 'euc') ('num_hidden_layers', 8) ('layer_size', 2) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[-0.15720690092409018, -0.14247748832243268, -0.12850804823155815, -0.11530817137390681, -0.10288528304281086, -0.09124405065705954, -0.0803863367336779, -0.07031100243138, -0.06101343595947184, -0.05248567539846993, -0.044715959951508344, -0.03768880007979525, -0.03138474738881336, -0.025780453459112174, -0.020848560166575547, -0.01655806318253661, -0.012874213504027843, -0.009759015909256208, -0.00717146869121299, -0.005068109912187202, -0.0034035646775374406, -0.0021311270037871477, -0.0012034657038642038, -0.0005733757996930766, -0.00019455766087972393, -2.2258970673760814e-05, -1.3984054349158725e-05, -0.00013023003056478188, -0.0003348665040709964, -0.0005957423660842842, -0.0008847962136442344, -0.0011770760042537631, -0.0014548525124100653, -0.0017061419279764678, -0.001917431339678588, -0.002077630963694954, -0.0021829148866203685, -0.0022356869116755274, -0.002239180670440044, -0.002193282157268772, -0.0020960172977082525, -0.0019463643490094107, -0.001743279918177798, -0.0014854367117722589, -0.0011860615640371108, -0.000847913599922423, -0.0005027831170920649, -0.0002074618179286336, -3.10682440545218e-05, -5.794092473587753e-06]\n",
      "Fold 1\n",
      "[-0.15720690092409018, -0.1424778172334309, -0.12850915973981403, -0.11531079884855355, -0.1028901803995168, -0.09125219601829215, -0.08039877453959177, -0.07032871418359266, -0.06103754487286839, -0.052517123141483824, -0.044755642891621816, -0.03773738711426211, -0.03144264718190937, -0.02584770758474919, -0.020924895825747525, -0.016642655183214394, -0.012965846151744342, -0.009855866553498238, -0.007271177658470851, -0.005167857925488573, -0.003499978363886491, -0.0022204250480475363, -0.0012815015015488207, -0.0006358305230180772, -0.0002370381009264566, -4.0361356310913976e-05, -3.6500329978483848e-06, -8.770611099340186e-05, -0.00025705043918522463, -0.0004801747736431494, -0.0007298662239920706, -0.000982215272352649, -0.0012202091643993551, -0.0014326847298997691, -0.0016072220834593143, -0.001733810251675294, -0.0018095674624616365, -0.001837209988562849, -0.00181975402305401, -0.0017566077323953877, -0.0016454557864389319, -0.001485140405923957, -0.0012754653289313023, -0.0010192305787661837, -0.0007364352847534228, -0.00044344052853029226, -0.00018490750000577094, -2.4795694958390513e-05, -1.438494055649997e-05, -0.00011050931229550365]\n",
      "Fold 2\n",
      "[-0.15720690092409018, -0.14247494291445473, -0.12849879654885132, -0.11528671995067952, -0.10284487713982893, -0.09117705595176417, -0.08028448047268899, -0.0701656842713192, -0.06081634518984802, -0.05222898060057646, -0.04439305419550821, -0.0372946701484298, -0.030916658508976624, -0.025238443449686176, -0.020235993507392136, -0.015882148603526325, -0.012146396533340598, -0.008995306866599995, -0.006392666445157236, -0.004299749284897736, -0.002675748584782145, -0.0014782305842739873, -0.0006635593399684225, -0.00018730078682871465, -5.074660915260765e-06, -7.279147386474172e-05, -0.0003474083881362944, -0.0007875073665470911, -0.0013537188195722472, -0.0020092184614353137, -0.0027202072920309295, -0.0034541020646230436, -0.004187615680531165, -0.0049002082117282075, -0.00557024303907383, -0.006177007540594692, -0.006705021416087753, -0.0071498993925669385, -0.007514978509438608, -0.007791892872816231, -0.007981043809776711, -0.008085048679286722, -0.008108408769677888, -0.008057222152143328, -0.007964243311994634, -0.007808906520696102, -0.007591638391664768, -0.0073223746478563445, -0.007008926826839401, -0.006663148542590536]\n",
      "Fold 3\n",
      "[-0.15720690092409018, -0.14247710308650352, -0.12850655366043284, -0.11530472709287287, -0.10287876655698946, -0.0912331942761131, -0.08036980373343239, -0.07028734675763082, -0.060981283199483594, -0.05244370551851718, -0.04466306446803281, -0.03762410105817393, -0.03130770683341977, -0.025690992742144703, -0.020747184477833303, -0.016445825184420837, -0.012752797427416196, -0.009630911311737655, -0.007039855844033438, -0.00493694300345382, -0.0032774173230365466, -0.0020151549000828606, -0.0011034219602266138, -0.0004952659875732124, -0.00014455795138212935, -6.441733406026273e-06, -3.8259210177749026e-05, -0.00019996771452768236, -0.00045478659386155584, -0.0007695500790039222, -0.0011151744265300856, -0.0014654597796586177, -0.0018015401579627444, -0.0021103210900184077, -0.0023769431638824834, -0.0025887354652105454, -0.002740519653529505, -0.0028339439979625514, -0.0028725726353757697, -0.0028571032103397176, -0.002786589626274205, -0.002661753016250712, -0.0024838572764671607, -0.0022511442287571626, -0.0019718843672016373, -0.001629267782716104, -0.0012311768593280537, -0.00081041125178416, -0.00042314006916921443, -0.0001434719401922635]\n",
      "Fold 4\n",
      "[-0.15720690092409018, -0.14247589815455663, -0.1285022366989219, -0.11529473407761048, -0.10285989788931293, -0.09120193385597553, -0.08032227609158094, -0.07021950355900874, -0.06088923013533365, -0.05232377050197923, -0.044512088101876346, -0.03743972948951191, -0.031088614963332484, -0.0254371313651367, -0.02046011655184543, -0.016128721332062668, -0.012411037786256296, -0.009271807953693312, -0.006672979563367765, -0.004574010869598633, -0.0029323317425538065, -0.0017037125687464627, -0.0008429875775746165, -0.0003044784298866787, -4.282078648221166e-05, -1.3430683194926019e-05, -0.00017317898176694158, -0.00048093682621574985, -0.0008983600265393132, -0.0013899791303952913, -0.0019239017972292327, -0.0024701741278327916, -0.0030072963903342576, -0.003518365220680053, -0.003984644291106454, -0.004388968497673673, -0.004720974755146434, -0.004978386930570178, -0.005164519830907599, -0.005277147758212308, -0.005318229207232905, -0.005292370169842409, -0.005205724988218918, -0.005065431153802091, -0.004899470029686714, -0.004693122753963053, -0.004448610112108842, -0.004173276683663296, -0.003874626747276011, -0.0035632772675548985]\n",
      "----- Combination 7 -----\n",
      "('model_type', 'euc') ('num_hidden_layers', 8) ('layer_size', 16) ('lr', 0.02) ('weight_decay', 0.02) ('batch_size', 1024) ('epochs', 50) ('curvature', -1)\n",
      "Fold 0\n",
      "[-0.02829170901554212, -0.001005044792843135, -0.005273076350181594, -0.01204597139618846, -0.01037184028423277, -0.005320988839500274, -0.001664854590867515, -0.0001128578043392281, -0.00020462615164773545, -0.0010399822733504482, -0.001900348587872136, -0.0024576896765500233, -0.002601858968094506, -0.002384076592905071, -0.0019398511802233287, -0.0013940453815495246, -0.0008656300196676625, -0.00043934118596600236, -0.00015766915600168296, -2.2320010890863884e-05, -4.584328939571947e-06, -5.828115416495194e-05, -0.00013569000608826265, -0.00020015109597437686, -0.0002326080275230069, -0.0002271877196822203, -0.00019066163298742111, -0.0001360722221654953, -7.920532331007202e-05, -3.281548855027516e-05, -5.682192927292107e-06, -8.236115609516759e-07, -1.5579676637456075e-05, -4.382218719101161e-05, -7.7670332424562e-05, -0.00010893071642170682, -0.00013308777846132713, -0.00014622151862142552, -0.0001466752067309507, -0.00013593729932082077, -0.00011665155673989958, -9.28305232097415e-05, -6.81238793025507e-05, -4.559349252808431e-05, -2.7295936083193695e-05, -1.4098928372563435e-05, -5.8769182682549825e-06, -1.481633559397011e-06, -7.180190331190772e-08, -2.523963635869819e-07]\n",
      "Fold 1\n",
      "[-0.028283673367480944, -0.0009716518582003619, -0.005704414088699261, -0.013246033164152848, -0.011753535857870201, -0.006330376921016567, -0.0022264526182058653, -0.0002749369130281565, -7.42698143538778e-05, -0.0007227622253762611, -0.0014930466139626564, -0.002021568467763357, -0.002182970400794737, -0.002000529740368684, -0.0016027780370622136, -0.0011141486971362191, -0.0006477384811689468, -0.0002864187568949461, -7.076118320403779e-05, -2.0164981084924705e-07, -4.2609347681299425e-05, -0.00014790086891558474, -0.0002662185613766521, -0.0003592724805034919, -0.0004055384600107903, -0.0004007753480814724, -0.00035300624265555136, -0.0002775356882880331, -0.00019286648175276255, -0.00011448838166727704, -5.363884124820473e-05, -1.596303175599445e-05, -8.262674449088792e-07, -3.325414638766233e-06, -1.656680831430002e-05, -3.280990611953527e-05, -4.6843483397562835e-05, -5.513158892034298e-05, -5.5617773544458515e-05, -4.9169958672212744e-05, -3.7839569258180106e-05, -2.472255947427726e-05, -1.2768127585882638e-05, -4.214002312652454e-06, -2.5058912211939344e-07, -1.0116859148201485e-06, -5.595075991182696e-06, -1.2593913449432392e-05, -2.0978031145535425e-05, -2.824085837960233e-05]\n",
      "Fold 2\n",
      "[-0.02875493527168116, -0.0016376414826937413, -0.001292236160294502, -0.0028711988571838987, -0.0013867764823645157, -4.6428201285086956e-05, -0.0005729821579585348, -0.0025078166485563713, -0.004872188689686752, -0.006900020505711479, -0.008067539644166066, -0.008311122819813832, -0.007916009845044591, -0.00706755452146246, -0.0059739065344543985, -0.004822386445291427, -0.003752290826663396, -0.00284548331408363, -0.0021348480388572177, -0.0016154929905836113, -0.0012640940270651768, -0.0010519120946128613, -0.0009480327958939494, -0.0009313639672445806, -0.0009876204667484956, -0.001107683635935608, -0.0012828400669893103, -0.0015059337375487036, -0.00176529283615956, -0.0020411662484978166, -0.0023212568025614555, -0.0025868404371331977, -0.00282360818205718, -0.003020538367627612, -0.003167638601760503, -0.003259135764159815, -0.003291989403550799, -0.003269245628353623, -0.0031991743885031454, -0.0030915901290493597, -0.0029577583182716083, -0.002809410353026065, -0.0026576071125470335, -0.0025048094113357955, -0.002362118223449894, -0.002240315598385889, -0.0021426402722644067, -0.002069891219235842, -0.002021000802202577, -0.0019936621971750057]\n",
      "Fold 3\n",
      "[-0.02828357029674522, -0.001055924458392088, -0.004661023493769179, -0.01056826407177458, -0.008594774917793924, -0.004025398238128863, -0.0009965361051744726, -3.700799286576739e-06, -0.0005048339668873858, -0.0015779688653259072, -0.0025437547671223193, -0.0031231121500250314, -0.0032305394148863797, -0.002956622620627014, -0.002434280630652541, -0.0018039686874051775, -0.0011895405293596006, -0.0006784767556249349, -0.00031498866292611893, -0.00010190229489870362, -1.2070134818076284e-05, -3.2958926012849332e-06, -3.122074591788149e-05, -6.16422145989226e-05, -7.501012082045122e-05, -6.690832470135355e-05, -4.438873344603245e-05, -1.8954633941081767e-05, -2.2591111217273863e-06, -2.972066496242931e-06, -2.5455431157839215e-05, -6.836260998799304e-05, -0.0001259807799938173, -0.00019003550978879957, -0.000250511822408539, -0.0003000071324861242, -0.0003341804853356223, -0.00034776182931950395, -0.000342972673094355, -0.000321905249749177, -0.00028837534255088393, -0.0002483251278213583, -0.00020627276013862605, -0.00016605715884399075, -0.00013028733224484945, -0.00010024217015858206, -7.629398125708065e-05, -5.7257406816058065e-05, -4.434970435940322e-05, -3.640068922527995e-05]\n",
      "Fold 4\n",
      "[-0.028475554389021385, -0.0013306235725496496, -0.0027505338420068526, -0.005968744418802352, -0.003957093352820351, -0.001050585233246304, -4.1742204426320484e-07, -0.0007455830113360928, -0.002397831898688141, -0.004100614357787524, -0.0052362851545815214, -0.0056577779072357615, -0.005467513353900388, -0.004843112969244556, -0.00398024911776429, -0.003055325811845311, -0.002196654323356917, -0.0014871961022844271, -0.0009553093762080245, -0.000589992180276111, -0.00036054038590149773, -0.00023000723215593766, -0.00016562761051908126, -0.00014508567436744002, -0.0001559154381414185, -0.00019522261439641753, -0.00026372342338309984, -0.00036315987113444415, -0.0004948347616997584, -0.0006527336121791016, -0.0008268421673769399, -0.0010042050937311142, -0.0011741604218089563, -0.0013200985700332346, -0.001424709824127346, -0.0014928342785895943, -0.0015202884737706146, -0.0015097980456735272, -0.001466875909875709, -0.0013982675686081691, -0.0013115280527125073, -0.0012150160234358776, -0.0011167389056203625, -0.0010228741130249297, -0.0009374390054230908, -0.0008575384439082345, -0.0007934916648479895, -0.0007459252369079739, -0.0007142384397693657, -0.0006970676603572645]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "param_eval_stats = []\n",
    "\n",
    "for i, params in enumerate(param_combinations):\n",
    "    print(f'----- Combination {i} -----')\n",
    "    print(*zip(param_grid.keys(), params))\n",
    "    model_type, num_hidden_layers, layer_size, lr, weight_decay, batch_size, epochs, curvature = params\n",
    "    # subset_frac, subset_seed, model_type, num_hidden_layers, layer_size, lr, weight_decay, batch_size, epochs, curvature = params\n",
    "    # val_indices, train_indices = util.get_fold_indices_rand(NUM_SAMPLE_TYPES, NUM_SAMPLES_PER_TYPE, FOLDS)\n",
    "    # np.random.seed(subset_seed)\n",
    "    # train_indices = [np.array(\n",
    "    #                     [list(range(val_i*NUM_SAMPLES_PER_TYPE,(val_i+1)*NUM_SAMPLES_PER_TYPE))\n",
    "    #                     for val_i in np.random.permutation(val_is[::NUM_SAMPLES_PER_TYPE]//NUM_SAMPLES_PER_TYPE)]\n",
    "    #                     [::int(1/subset_frac)]\n",
    "    #                  ).flatten() for val_is in train_indices]\n",
    "\n",
    "    for fold, (fold_train_indices, fold_val_indices) in enumerate(zip(train_indices, val_indices)):\n",
    "        print(f'Fold {fold}')\n",
    "\n",
    "        fold_train_X = train_X[fold_train_indices]\n",
    "        fold_train_y = train_y[fold_train_indices]\n",
    "        fold_val_X   = val_X[fold_val_indices]\n",
    "        fold_val_y   = val_y[fold_val_indices]\n",
    "\n",
    "        train_dataset = CustomDataset(fold_train_X, fold_train_y)\n",
    "        val_dataset = CustomDataset(fold_val_X, fold_val_y)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        if model_type == 'hyp':\n",
    "            manifold = PoincareBall(c=Curvature(curvature))\n",
    "        elif model_type == 'euc':\n",
    "            manifold = None\n",
    "\n",
    "        if model_type == 'hyp':\n",
    "            model = HYP_MLP(input_size=train_X.shape[1],\n",
    "                            output_size=train_y.shape[1],\n",
    "                            layer_size=layer_size,\n",
    "                            num_hidden_layers=num_hidden_layers,\n",
    "                            manifold=manifold).to(device)\n",
    "        elif model_type == 'euc':\n",
    "            model = EUC_MLP(input_size=train_X.shape[1],\n",
    "                            output_size=train_y.shape[1],\n",
    "                            layer_size=layer_size,\n",
    "                            num_hidden_layers=num_hidden_layers).to(device)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        if model_type == 'hyp':\n",
    "            optimizer = RiemannianAdam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif model_type == 'euc':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        eval_stats = {'loss': {'train': [], 'val': []}, 'mae': {'train': [], 'val': []}}\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            if model_type == 'hyp':\n",
    "                eval_stats['loss']['train'].append(hyp_train_model(model, train_loader, criterion, optimizer, manifold, device))\n",
    "                # eval_stats['loss']['val'].append(util.h_evaluate_loss(model, val_loader, criterion, manifold, device))\n",
    "\n",
    "                # eval_stats['mae']['train'].append(util.h_evaluate_r2(model, train_loader, manifold, device))\n",
    "                eval_stats['mae']['val'].append(util.h_evaluate_r2(model, val_loader, manifold, device))\n",
    "            elif model_type == 'euc':\n",
    "                eval_stats['loss']['train'].append(euc_train_model(model, train_loader, criterion, optimizer, device))\n",
    "                # eval_stats['loss']['val'].append(util.evaluate_loss(model, val_loader, criterion, device))\n",
    "\n",
    "                # eval_stats['mae']['train'].append(util.evaluate_r2(model, train_loader, device))\n",
    "                eval_stats['mae']['val'].append(util.evaluate_r2(model, val_loader, device))\n",
    "\n",
    "        print(eval_stats['mae']['val'])\n",
    "        param_eval_stats.append(eval_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 50)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.array([s['mae']['val'] for s in param_eval_stats])\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0098135  -0.01482149 -0.02619709  0.0740778  -0.02478348  0.05106715\n",
      "  0.1211282   0.09496893  0.11628845  0.11730955  0.05428587  0.04863835\n",
      " -0.00015663  0.04706135  0.00950831  0.12907991  0.15787021  0.15522702\n",
      "  0.1610022   0.18868853]\n",
      "[ 0.13872422  0.10314128  0.23168072  0.14809439  0.15107284  0.13625879\n",
      "  0.2014225   0.2177335   0.14670567  0.15123508 -0.00000579 -0.00000365\n",
      " -0.00000507 -0.00000644 -0.00001343 -0.00000007 -0.0000002  -0.00004643\n",
      " -0.00000226 -0.00000042]\n"
     ]
    }
   ],
   "source": [
    "maxs = values.max(axis=1)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(maxs[:len(maxs)//2])\n",
    "print(maxs[len(maxs)//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23168072239892634"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3965931364.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[107], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    [ 0.04208212  0.09751442 -0.04606401  0.0712357  -0.00400633  0.13748352\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# with extra val\n",
    "[ 0.04208212  0.09751442 -0.04606401  0.0712357  -0.00400633  0.13748352\n",
    "  0.09081208 -0.04386033 -0.02395997 -0.15846087  0.03498488  0.07202289\n",
    " -0.02085818  0.01120551 -0.00218182  0.13168304  0.13303923  0.0325146\n",
    " -0.07400053 -0.08542335]\n",
    "[ 0.17240834  0.1121149   0.04307168  0.26821662  0.03719734  0.09071867\n",
    "  0.23690227  0.00999958  0.13295279 -0.00147542 -0.00095303 -0.00229772\n",
    " -0.00016626 -0.000014   -0.00008467 -0.00040337 -0.00125949 -0.00438234\n",
    " -0.00001444 -0.00006241]\n",
    "\n",
    "# with extra test\n",
    "[ 0.01153104 -0.0269716  -0.0306455   0.02903555 -0.03208602  0.03991365\n",
    "  0.11761132  0.10063213  0.12268068  0.11826183  0.05152496  0.00086766\n",
    "  0.10645656  0.09313301  0.0008321   0.08007883  0.11517472  0.13551555\n",
    "  0.17608034  0.16115679]\n",
    "[ 0.14551757  0.12194946  0.22337597  0.15371139  0.15394668  0.11856814\n",
    "  0.15925483  0.1400816   0.14827459  0.16247329 -0.00000001 -0.00000005\n",
    " -0.00001019 -0.00000004 -0.00000907 -0.00000007 -0.00000001 -0.0000055\n",
    " -0.00000012 -0.000084  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (4000728462.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[108], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    [ 0.02833115  0.04921563 -0.03776849  0.02765915 -0.0222859   0.15873057\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# no extra val\n",
    "[ 0.02833115  0.04921563 -0.03776849  0.02765915 -0.0222859   0.15873057\n",
    "  0.10190526 -0.05050924 -0.01983954 -0.13903793  0.06714506  0.10148732\n",
    " -0.01670278  0.01695462 -0.00483505  0.20704623  0.12806648  0.02366684\n",
    "  0.0352953  -0.00352358]\n",
    "[ 0.1601424   0.06245344  0.04459166  0.2675162   0.03486414  0.04170656\n",
    "  0.19996282  0.00993206  0.1636994   0.01013138 -0.00083778 -0.00307038\n",
    "  0.00000003 -0.00000007 -0.00004749 -0.00064094 -0.0026431  -0.00363318\n",
    " -0.00000012 -0.00000885]\n",
    "\n",
    "# no extra test\n",
    "[-0.0098135  -0.01482149 -0.02619709  0.0740778  -0.02478348  0.05106715\n",
    "  0.1211282   0.09496893  0.11628845  0.11730955  0.05428587  0.04863835\n",
    " -0.00015663  0.04706135  0.00950831  0.12907991  0.15787021  0.15522702\n",
    "  0.1610022   0.18868853]\n",
    "[ 0.13872422  0.10314128  0.23168072  0.14809439  0.15107284  0.13625879\n",
    "  0.2014225   0.2177335   0.14670567  0.15123508 -0.00000579 -0.00000365\n",
    " -0.00000507 -0.00000644 -0.00001343 -0.00000007 -0.0000002  -0.00004643\n",
    " -0.00000226 -0.00000042]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BEST MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hyp_params = {\n",
    "    'model_type': 'hyp',\n",
    "    'num_hidden_layers': 1,\n",
    "    'layer_size': 32,\n",
    "    'lr': 0.02,\n",
    "    'weight_decay': 0.01,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 40,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "all_euc_params = {\n",
    "    'model_type': 'euc',\n",
    "    'num_hidden_layers': 0,\n",
    "    'layer_size': 128,\n",
    "    'lr': 0.01,\n",
    "    'weight_decay': 0.03,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 40,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "\n",
    "both_hyp_params = {\n",
    "    'model_type': 'hyp',\n",
    "    'num_hidden_layers': 1,\n",
    "    'layer_size': 1024,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.01,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 20,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "both_euc_params = {\n",
    "    'model_type': 'euc',\n",
    "    'num_hidden_layers': 0,\n",
    "    'layer_size': 128,\n",
    "    'lr': 0.005,\n",
    "    'weight_decay': 0.04,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 20,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "\n",
    "aroma_hyp_params = {\n",
    "    'model_type': 'hyp',\n",
    "    'num_hidden_layers': 2,\n",
    "    'layer_size': 64,\n",
    "    'lr': 0.03,\n",
    "    'weight_decay': 0.04,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 20,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "aroma_euc_params = {\n",
    "    'model_type': 'euc',\n",
    "    'num_hidden_layers': 1,\n",
    "    'layer_size': 128,\n",
    "    'lr': 0.005,\n",
    "    'weight_decay': 0.04,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 20,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "\n",
    "flavour_hyp_params = {\n",
    "    'model_type': 'hyp',\n",
    "    'num_hidden_layers': 1,\n",
    "    'layer_size': 1024,\n",
    "    'lr': 0.01,\n",
    "    'weight_decay': 0.02,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 20,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "flavour_euc_params = {\n",
    "    'model_type': 'euc',\n",
    "    'num_hidden_layers': 1,\n",
    "    'layer_size': 512,\n",
    "    'lr': 0.005,\n",
    "    'weight_decay': 0.04,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 20,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "\n",
    "overall_hyp_params = {\n",
    "    'model_type': 'hyp',\n",
    "    'num_hidden_layers': 8,\n",
    "    'layer_size': 16,\n",
    "    'lr': 0.03,\n",
    "    'weight_decay': 0.04,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 20,\n",
    "    'curvature': -1\n",
    "}\n",
    "\n",
    "\n",
    "overall_euc_params = {\n",
    "    'model_type': 'euc',\n",
    "    'num_hidden_layers': 2,\n",
    "    'layer_size': 4,\n",
    "    'lr': 0.03,\n",
    "    'weight_decay': 0.04,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 40,\n",
    "    'curvature': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[-0.0016471249812195499, 0.0008404496078157075, 0.0008789222402491026, 0.00026401048720692266, 0.0003331109070743299, 0.0004570609171076212, 0.00028211979731374015, -0.00012335131405083466, -0.0007544967974100203, -0.0014049407529841407, -0.0018472581612558603, -0.0019103508267446223, -0.0016837539439404914, -0.0012572835092492518, -0.0006824067841868509, -8.56038690002503e-05, 0.0005095604138050103, 0.0011671912078867752, 0.0022753924535856562, 0.00453379377207852, 0.009292709399278398, 0.01986643544624278, 0.039115261073036645, 0.0718638071190143, 0.1188655638233731, 0.17002022935495142, 0.19550408511191197, 0.19648507487699363, 0.1924564211733809, 0.16091164366397714, 0.15995026404876644, 0.1297557837973078, 0.031077517281469236, -0.006241521395857541, -0.06089570196338179, -0.1504494587522669, -0.22573474813469896, -0.2598351816864206, -0.1641191878405106, -0.13666728522265936]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "param_eval_stats = []\n",
    "\n",
    "model_type, num_hidden_layers, layer_size, lr, weight_decay, batch_size, epochs, curvature = overall_euc_params.values()\n",
    "\n",
    "for fold in [0]:\n",
    "    print(f'Fold {fold}')\n",
    "\n",
    "    fold_train_X = train_X\n",
    "    fold_train_y = train_y\n",
    "    fold_val_X   = test_X\n",
    "    fold_val_y   = test_y\n",
    "\n",
    "    train_dataset = CustomDataset(fold_train_X, fold_train_y)\n",
    "    val_dataset = CustomDataset(fold_val_X, fold_val_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    if model_type == 'hyp':\n",
    "        manifold = PoincareBall(c=Curvature(curvature))\n",
    "    elif model_type == 'euc':\n",
    "        manifold = None\n",
    "\n",
    "    if model_type == 'hyp':\n",
    "        model = HYP_MLP(input_size=train_X.shape[1],\n",
    "                        output_size=train_y.shape[1],\n",
    "                        layer_size=layer_size,\n",
    "                        num_hidden_layers=num_hidden_layers,\n",
    "                        manifold=manifold).to(device)\n",
    "    elif model_type == 'euc':\n",
    "        model = EUC_MLP(input_size=train_X.shape[1],\n",
    "                        output_size=train_y.shape[1],\n",
    "                        layer_size=layer_size,\n",
    "                        num_hidden_layers=num_hidden_layers).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if model_type == 'hyp':\n",
    "        optimizer = RiemannianAdam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif model_type == 'euc':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    eval_stats = {'loss': {'train': [], 'val': []}, 'mae': {'train': [], 'val': []}}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if model_type == 'hyp':\n",
    "            eval_stats['loss']['train'].append(hyp_train_model(model, train_loader, criterion, optimizer, manifold, device))\n",
    "            eval_stats['loss']['val'].append(util.h_evaluate_loss(model, val_loader, criterion, manifold, device))\n",
    "\n",
    "            eval_stats['mae']['train'].append(util.h_evaluate_r2(model, train_loader, manifold, device))\n",
    "            eval_stats['mae']['val'].append(util.h_evaluate_r2(model, val_loader, manifold, device))\n",
    "        elif model_type == 'euc':\n",
    "            eval_stats['loss']['train'].append(euc_train_model(model, train_loader, criterion, optimizer, device))\n",
    "            eval_stats['loss']['val'].append(util.evaluate_loss(model, val_loader, criterion, device))\n",
    "\n",
    "            eval_stats['mae']['train'].append(util.evaluate_r2(model, train_loader, device))\n",
    "            eval_stats['mae']['val'].append(util.evaluate_r2(model, val_loader, device))\n",
    "\n",
    "    print(eval_stats['mae']['val'])\n",
    "    param_eval_stats.append(eval_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hyp = [0.019803949968528807, 0.0435701059508602, 0.061787428612528394, 0.07816493353612519, 0.09188836643619001, 0.10633945467192137, 0.11765106859990054, 0.12557091311898153, 0.1303479467273797, 0.1335712564466234, 0.1352438325475701, 0.1352469647004896, 0.13541587819513887, 0.13655426473987384, 0.13710621639963136, 0.13749532752232935, 0.13754431289023716, 0.13744183510525848, 0.1357395170110222]\n",
    "all_euc = [0.09737664483213233, 0.1767868848011554, 0.21354389897412873, 0.22753877842580006, 0.24069759495388496, 0.24301335525495277, 0.23955938943268723, 0.23781773055086153, 0.24060031116891045, 0.2369816412643267, 0.23955118897437433, 0.23740763285455752, 0.2371960160218606, 0.2380149019077428, 0.2381129158465512, 0.23935000769944764, 0.23772098636139222, 0.2385743222080775, 0.23919263473584199, 0.23897391007109317, 0.23936433936272533, 0.2419476466047754, 0.2421968872716602, 0.24159459048992712, 0.23848953202992895, 0.2413499438694181, 0.2408379614822577, 0.2390444755477261, 0.23554761122339563, 0.24006158161447685, 0.24116588180987042, 0.24292095199226915, 0.240927223999066, 0.2397956176183722, 0.24026381640389707, 0.2396308440271975, 0.23838257426811515, 0.2402450469319777, 0.2407518847178515, 0.2403430622203345, 0.24045320856138003, 0.2374691725123596, 0.24170814650317263, 0.23961948022324925, 0.2384370067089982, 0.2386866166946942, 0.24092050224592249, 0.23640456430700724, 0.24183436998181398]\n",
    "\n",
    "both_hyp = [-0.017700818636931438, -0.0064280704478765546, 0.004076024980897919, 0.013337835030754579, 0.02207101578586137, 0.030594178508889555, 0.03920506570187111, 0.0471646934949885, 0.05383175009655616, 0.0593832816481977, 0.06406316946537088, 0.06793349075032107, 0.07113062287326259, 0.073710003232364, 0.07601868837076567, 0.07828042529757168, 0.08043943927648035, 0.08269077293800156, 0.0849947337222407, 0.0872735891258831, 0.08942827345262971, 0.09143803458607208, 0.09321348862354645, 0.0947551589335554, 0.09609227282335094, 0.09729046892260189, 0.098439522980781, 0.09959134282389555, 0.10084808949637475]\n",
    "both_euc = [0.056511710416177856, 0.10463818328932575, 0.14037638840046365, 0.16748315203178654, 0.18754794652031187, 0.2010600461558006, 0.20524386588415133, 0.2042004572834431, 0.20354526830834954, 0.20195621300404662, 0.19751700051892038, 0.19681881999693004, 0.1993068902698353, 0.20085225170433121, 0.20224081689963763, 0.20405645423287055, 0.2034414048003447, 0.20397168106206917, 0.20476092835668636]\n",
    "\n",
    "aroma_hyp = [0.043506018002840624, 0.07644638210377158, 0.0940139222387848, 0.10149722663771008, 0.11074721451438532, 0.1196359887500886, 0.12065519820217822, 0.11985206742523302, 0.11425990975945481]\n",
    "aroma_euc = [0.016581975803421488, 0.030333710664162038, 0.047895055812664275, 0.06699653444759006, 0.09174940126154342, 0.12010923117978736, 0.1464214006835298, 0.16524764381476148, 0.17150248157663384, 0.17411601206397426, 0.17528092990688052, 0.17037950273857266, 0.1633278336199154, 0.16632210710399928, 0.15986681668112798, 0.16357377699508957, 0.15743396675175042, 0.165121161682967, 0.16069596440505005, 0.16706755326414127, 0.16413768414428948, 0.16785090714189885, 0.16606082513356196, 0.1655280100847114, 0.1662923298653558, 0.1666638124114819, 0.16031185100912027, 0.166550977476877, 0.1552999873922548]\n",
    "\n",
    "flavour_hyp = [0.03986696024248919, 0.1059427348635158, 0.12762229583113024, 0.13614029085940363, 0.1439757173779101, 0.15752042236232708, 0.16761940161870684, 0.17142779330057306, 0.17251813971869076]\n",
    "flavour_euc = [0.06497013702409148, 0.13407108763787928, 0.17481342412987114, 0.20926418995288273, 0.23773597117300363, 0.23670133899144646, 0.2293672879954037, 0.2331755483733003, 0.23736134267460818, 0.23080337050022698, 0.22463794102323958, 0.2356105361284019, 0.2165014674661587, 0.2374054298258675, 0.2209796991765166, 0.23414963636455713, 0.22626198058190564, 0.23971467640855162, 0.2334995355039221, 0.23590218603027943, 0.23600973078593288, 0.23098995490800495, 0.23654289606072723, 0.22748120035108962, 0.2339286736734794, 0.22804065303458992, 0.2346826723438091, 0.23208283690060139, 0.23976255136723681]\n",
    "\n",
    "overall_hyp = [-2.331213413290907, -1.349686849698061, -0.311931490718135, -0.12774107035998927, -0.02028527387369139, 0.007657482213295319, 0.029656275106347274, 0.06475491343520179, 0.1005532014770506, 0.10200877654932994, 0.11833868393227087, 0.1435175682912322, 0.1516750927217736, 0.14587939085914825]\n",
    "overall_euc = [0.0008006451102687828, 0.005526001209553377, 0.03222881447119552, 0.08325441947658985, 0.15880639540215313, 0.1988655537783417, 0.18734887150044177, 0.17252088658173192, 0.17080140823672618]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hyp = 0.13433516699034279\n",
    "all_euc = 0.24536668912211346\n",
    "\n",
    "both_hyp =\n",
    "both_euc =\n",
    "\n",
    "aroma_hyp =\n",
    "aroma_euc =\n",
    "\n",
    "flavour_hyp =\n",
    "flavour_euc =\n",
    "\n",
    "overall_hyp = 0.19648507487699363\n",
    "overall_euc = 0.14878169179788303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1357395170110222\n",
      "0.24183436998181398\n",
      "0.5612912549247232\n",
      "\n",
      "0.10084808949637475\n",
      "0.20476092835668636\n",
      "0.4925162740066353\n",
      "\n",
      "0.11425990975945481\n",
      "0.1552999873922548\n",
      "0.7357367613357143\n",
      "\n",
      "0.17251813971869076\n",
      "0.23976255136723681\n",
      "0.7195374704469595\n",
      "\n",
      "0.14587939085914825\n",
      "0.17080140823672618\n",
      "0.854087752350164\n"
     ]
    }
   ],
   "source": [
    "print(all_hyp[-1])\n",
    "print(all_euc[-1])\n",
    "print(all_hyp[-1]/all_euc[-1])\n",
    "print()\n",
    "print(both_hyp[-1])\n",
    "print(both_euc[-1])\n",
    "print(both_hyp[-1]/both_euc[-1])\n",
    "print()\n",
    "print(aroma_hyp[-1])\n",
    "print(aroma_euc[-1])\n",
    "print(aroma_hyp[-1]/aroma_euc[-1])\n",
    "print()\n",
    "print(flavour_hyp[-1])\n",
    "print(flavour_euc[-1])\n",
    "print(flavour_hyp[-1]/flavour_euc[-1])\n",
    "print()\n",
    "print(overall_hyp[-1])\n",
    "print(overall_euc[-1])\n",
    "print(overall_hyp[-1]/overall_euc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(overall_hyp)\n",
    "plt.plot(overall_euc)\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
