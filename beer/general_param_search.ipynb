{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from hypll import nn as hnn\n",
    "from hypll.tensors import TangentTensor\n",
    "from hypll.optim import RiemannianAdam\n",
    "from hypll.manifolds.poincare_ball import Curvature, PoincareBall\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((175000, 231), (175000, 50), (175, 231), (175, 50), (75, 231), (75, 50))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_X = pd.read_csv('../data/beer_features_train_samples.csv', index_col=0)\n",
    "df_train_y = pd.read_csv('../data/beer_labels_panel_train_samples.csv', index_col=0)\n",
    "df_val_X = pd.read_csv('../data/beer_features_train.csv', index_col=0)\n",
    "df_val_y = pd.read_csv('../data/beer_labels_panel_train.csv', index_col=0)\n",
    "df_test_X = pd.read_csv('../data/beer_features_test.csv', index_col=0)\n",
    "df_test_y = pd.read_csv('../data/beer_labels_panel_test.csv', index_col=0)\n",
    "\n",
    "train_X = df_train_X.values\n",
    "train_y = df_train_y.values\n",
    "val_X = df_val_X.values\n",
    "val_y = df_val_y.values\n",
    "test_X = df_test_X.values\n",
    "test_y = df_test_y.values\n",
    "\n",
    "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 35), (35, 70), (70, 105), (105, 140), (140, 175)]\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "NUM_SAMPLE_TYPES = len(val_X)\n",
    "NUM_SAMPLES_PER_TYPE = len(train_X) // NUM_SAMPLE_TYPES\n",
    "\n",
    "fold_nums = list(range(FOLDS))\n",
    "[num*NUM_SAMPLE_TYPES for num in fold_nums]\n",
    "[(num+1)*NUM_SAMPLE_TYPES for num in fold_nums]\n",
    "\n",
    "FOLD_INDICIES = util.get_fold_indices(NUM_SAMPLE_TYPES, FOLDS)\n",
    "\n",
    "# FOLD_INDICIES = list(zip([num*NUM_SAMPLE_TYPES//FOLDS for num in fold_nums],\n",
    "#                          [(num+1)*NUM_SAMPLE_TYPES//FOLDS for num in fold_nums]))\n",
    "\n",
    "print(FOLD_INDICIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom PyTorch dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Hyperbolic </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your MLP model\n",
    "class HYP_MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, layer_size, num_hidden_layers, manifold):\n",
    "        super(HYP_MLP, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.fc_in = hnn.HLinear(input_size, layer_size, manifold=manifold)\n",
    "        self.relu = hnn.HReLU(manifold=manifold)\n",
    "        self.hidden_fcs = nn.ModuleList([hnn.HLinear(layer_size, layer_size, manifold=manifold) for _ in range(num_hidden_layers)])\n",
    "        self.fc_out = hnn.HLinear(layer_size, output_size, manifold=manifold)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.relu(x)\n",
    "        for fc in self.hidden_fcs:\n",
    "            x = fc(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define training function\n",
    "def hyp_train_model(model, train_loader, criterion, optimizer, manifold, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tangents = TangentTensor(data=inputs, man_dim=-1, manifold=manifold)\n",
    "        manifold_inputs = manifold.expmap(tangents)\n",
    "\n",
    "        outputs = model(manifold_inputs)\n",
    "\n",
    "        loss = criterion(outputs.tensor, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> EUCLIDEAN </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your MLP model\n",
    "class EUC_MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, layer_size, num_hidden_layers):\n",
    "        super(EUC_MLP, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.fc_in = nn.Linear(input_size, layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_fcs = nn.ModuleList([nn.Linear(layer_size, layer_size) for _ in range(num_hidden_layers)])\n",
    "        self.fc_out = nn.Linear(layer_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.relu(x)\n",
    "        for fc in self.hidden_fcs:\n",
    "            x = fc(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define training function\n",
    "def euc_train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     'model_type': ['hyp', 'euc'],\n",
    "#     'num_hidden_layers': [0,1,2,4,8],\n",
    "#     'layer_size': [64,128,256],\n",
    "#     'lr': [0.001,0.003,0.01],\n",
    "#     'weight_decay': [0.001],\n",
    "#     'batch_size': [1024],\n",
    "#     'epochs': [10],\n",
    "#     'curvature': [-1]\n",
    "# }\n",
    "param_grid = {\n",
    "    'model_type': ['euc'],\n",
    "    'num_hidden_layers': [0],\n",
    "    'layer_size': [256],\n",
    "    'lr': [0.003],\n",
    "    'weight_decay': [0.001],\n",
    "    'batch_size': [1024],\n",
    "    'epochs': [10],\n",
    "    'curvature': [-1]\n",
    "}\n",
    "\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "len(param_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Combination 0 -----\n",
      "('model_type', 'euc') ('num_hidden_layers', 0) ('layer_size', 256) ('lr', 0.003) ('weight_decay', 0.001) ('batch_size', 1024) ('epochs', 10) ('curvature', -1)\n",
      "Fold 0\n",
      "(140000, 231)\n",
      "(140000, 50)\n",
      "(35, 231)\n",
      "(35, 50)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m         eval_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(euc_train_model(model, train_loader, criterion, optimizer, device))\n\u001b[1;32m     64\u001b[0m         eval_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(util\u001b[38;5;241m.\u001b[39mevaluate_loss(model, val_loader, criterion, device))\n\u001b[0;32m---> 66\u001b[0m         eval_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_r2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     67\u001b[0m         eval_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(util\u001b[38;5;241m.\u001b[39mevaluate_r2(model, val_loader, device))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/SynologyDrive/Drive/UVA/Year_4/thesis/master_thesis/beer/../util.py:283\u001b[0m, in \u001b[0;36mevaluate_r2\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    281\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 283\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     all_predictions\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    286\u001b[0m     all_targets\u001b[38;5;241m.\u001b[39mappend(targets\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m, in \u001b[0;36mEUC_MLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_fcs:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "param_eval_stats = []\n",
    "\n",
    "for i, params in enumerate(param_combinations):\n",
    "    print(f'----- Combination {i} -----')\n",
    "    print(*zip(param_grid.keys(), params))\n",
    "    model_type, num_hidden_layers, layer_size, lr, weight_decay, batch_size, epochs, curvature = params\n",
    "\n",
    "    for fold, (fold_start, fold_stop) in enumerate(FOLD_INDICIES):\n",
    "        print(f'Fold {fold}')\n",
    "\n",
    "        fold_train_X = train_X[[*list(range(fold_start*NUM_SAMPLES_PER_TYPE)), *list(range(fold_stop*NUM_SAMPLES_PER_TYPE, len(train_X)))]]\n",
    "        fold_train_y   =   train_y[[*list(range(fold_start*NUM_SAMPLES_PER_TYPE)), *list(range(fold_stop*NUM_SAMPLES_PER_TYPE, len(train_X)))]]\n",
    "        fold_val_X   = val_X[list(range(fold_start, fold_stop))]\n",
    "        fold_val_y     =   val_y[list(range(fold_start, fold_stop))]\n",
    "\n",
    "        train_dataset = CustomDataset(fold_train_X, fold_train_y)\n",
    "        val_dataset = CustomDataset(fold_val_X, fold_val_y)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        if model_type == 'hyp':\n",
    "            manifold = PoincareBall(c=Curvature(curvature))\n",
    "        elif model_type == 'euc':\n",
    "            manifold = None\n",
    "\n",
    "        if model_type == 'hyp':\n",
    "            model = HYP_MLP(input_size=train_X.shape[1],\n",
    "                            output_size=train_y.shape[1],\n",
    "                            layer_size=layer_size,\n",
    "                            num_hidden_layers=num_hidden_layers,\n",
    "                            manifold=manifold).to(device)\n",
    "        elif model_type == 'euc':\n",
    "            model = EUC_MLP(input_size=train_X.shape[1],\n",
    "                            output_size=train_y.shape[1],\n",
    "                            layer_size=layer_size,\n",
    "                            num_hidden_layers=num_hidden_layers).to(device)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        if model_type == 'hyp':\n",
    "            optimizer = RiemannianAdam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif model_type == 'euc':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        eval_stats = {'loss': {'train': [], 'val': []}, 'mae': {'train': [], 'val': []}}\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            if model_type == 'hyp':\n",
    "                eval_stats['loss']['train'].append(hyp_train_model(model, train_loader, criterion, optimizer, manifold, device))\n",
    "                eval_stats['loss']['val'].append(util.h_evaluate_loss(model, val_loader, criterion, manifold, device))\n",
    "\n",
    "                eval_stats['mae']['train'].append(util.h_evaluate_r2(model, train_loader, manifold, device))\n",
    "                eval_stats['mae']['val'].append(util.h_evaluate_r2(model, val_loader, manifold, device))\n",
    "            elif model_type == 'euc':\n",
    "                eval_stats['loss']['train'].append(euc_train_model(model, train_loader, criterion, optimizer, device))\n",
    "                eval_stats['loss']['val'].append(util.evaluate_loss(model, val_loader, criterion, device))\n",
    "\n",
    "                eval_stats['mae']['train'].append(util.evaluate_r2(model, train_loader, device))\n",
    "                eval_stats['mae']['val'].append(util.evaluate_r2(model, val_loader, device))\n",
    "\n",
    "        print(eval_stats['mae']['val'])\n",
    "        param_eval_stats.append(eval_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BEST MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'model_type': 'hyp',\n",
    "    'num_hidden_layers': 0,\n",
    "    'layer_size': 256,\n",
    "    'lr': 0.003,\n",
    "    'weight_decay': 0.001,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 10,\n",
    "    'curvature': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[0.12213091453452084, 0.1157001481513608, 0.11392419176270517, 0.11284872166569462, 0.11235204818697327, 0.11316860040285931, 0.11410305083931009, 0.11440463729762851, 0.11531641660826678, 0.11545186484785316]\n",
      "Fold 1\n",
      "[0.12096299774953018, 0.11402811528347077, 0.1115709905687423, 0.1118897793812911, 0.1114985346409828, 0.1117588181582547, 0.11141746955268837, 0.1142810874286106, 0.11433417468577468, 0.11649154963442707]\n",
      "Fold 2\n",
      "[0.12097428843572282, 0.11386955485352537, 0.11219742989391258, 0.11092534413860397, 0.11160005394126267, 0.1127382517547978, 0.11300108278119132, 0.11431947476444206, 0.11581559038693329, 0.11611106004460434]\n",
      "Fold 3\n",
      "[0.12102868091192692, 0.11407396279351424, 0.1130131419674709, 0.11212084167886255, 0.11195427368953009, 0.1131073585755835, 0.11292370143948416, 0.11325685402463381, 0.11433557809975682, 0.11559678845224834]\n",
      "Fold 4\n",
      "[0.12071365008458936, 0.1139570541445054, 0.11124207452797544, 0.11129954140646825, 0.11089288999148879, 0.11139676387325646, 0.11209375811332396, 0.11359856805827497, 0.11230533662240974, 0.11518638709884424]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model_type, num_hidden_layers, layer_size, lr, weight_decay, batch_size, epochs, curvature = best_params.values()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_X, train_y)):\n",
    "    print(f'Fold {fold}')\n",
    "    # fold_train_X, fold_val_X = train_X[train_idx], train_X[val_idx]\n",
    "    # fold_train_y, fold_val_y = train_y[train_idx], train_y[val_idx]\n",
    "    fold_train_X, fold_val_X = train_X[train_idx], test_X\n",
    "    fold_train_y, fold_val_y = train_y[train_idx], test_y\n",
    "    # fold_train_X, fold_val_X = train_X, test_X\n",
    "    # fold_train_y, fold_val_y = train_y, test_y\n",
    "\n",
    "    train_dataset = CustomDataset(fold_train_X, fold_train_y)\n",
    "    val_dataset = CustomDataset(fold_val_X, fold_val_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    if model_type == 'hyp':\n",
    "        manifold = PoincareBall(c=Curvature(curvature))\n",
    "    elif model_type == 'euc':\n",
    "        manifold = None\n",
    "\n",
    "    if model_type == 'hyp':\n",
    "        model = HYP_MLP(input_size=train_X.shape[1],\n",
    "                        output_size=train_y.shape[1],\n",
    "                        layer_size=layer_size,\n",
    "                        num_hidden_layers=num_hidden_layers,\n",
    "                        manifold=manifold).to(device)\n",
    "    elif model_type == 'euc':\n",
    "        model = EUC_MLP(input_size=train_X.shape[1],\n",
    "                        output_size=train_y.shape[1],\n",
    "                        layer_size=layer_size,\n",
    "                        num_hidden_layers=num_hidden_layers).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if model_type == 'hyp':\n",
    "        optimizer = RiemannianAdam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif model_type == 'euc':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    eval_stats = {'loss': {'train': [], 'val': []}, 'mae': {'train': [], 'val': []}}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if model_type == 'hyp':\n",
    "            eval_stats['loss']['train'].append(hyp_train_model(model, train_loader, criterion, optimizer, manifold, device))\n",
    "            eval_stats['loss']['val'].append(util.h_evaluate_loss(model, val_loader, criterion, manifold, device))\n",
    "\n",
    "            eval_stats['mae']['train'].append(util.h_evaluate_r2(model, train_loader, manifold, device))\n",
    "            eval_stats['mae']['val'].append(util.h_evaluate_r2(model, val_loader, manifold, device))\n",
    "        elif model_type == 'euc':\n",
    "            eval_stats['loss']['train'].append(euc_train_model(model, train_loader, criterion, optimizer, device))\n",
    "            eval_stats['loss']['val'].append(util.evaluate_loss(model, val_loader, criterion, device))\n",
    "\n",
    "            eval_stats['mae']['train'].append(util.evaluate_r2(model, train_loader, device))\n",
    "            eval_stats['mae']['val'].append(util.evaluate_r2(model, val_loader, device))\n",
    "\n",
    "    print(eval_stats['mae']['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold 0\n",
    "[0.09094981766612582, 0.09608602443769439, 0.10213084733073284, 0.10297098476158782, 0.1039252772204806, 0.10574258559121522, 0.10593447081943014, 0.1103528270397624, 0.10905810868205902, 0.11674655082317638]\n",
    "Fold 1\n",
    "[0.09124620536624219, 0.09588467278224783, 0.1109519321222205, 0.10871296762480671, 0.11322182908185724, 0.10604926039894355, 0.11641335699831064, 0.11669891168893905, 0.1163291967061507, 0.11563811270315874]\n",
    "Fold 2\n",
    "[0.08261279344412803, 0.0949209955128152, 0.10394174902203669, 0.11074634671414854, 0.10959598998285282, 0.10492545479477039, 0.10590842284461503, 0.10538532105083259, 0.10268829907521582, 0.10696282556494001]\n",
    "Fold 3\n",
    "[0.09143749197812866, 0.10686854162056632, 0.10184344301563328, 0.10983260881492879, 0.11453995365690633, 0.10643641196149398, 0.10807662045371369, 0.11264002132608508, 0.11569218070241385, 0.11172063540914148]\n",
    "Fold 4\n",
    "[0.08755047684265042, 0.09826624201788955, 0.10408250848514021, 0.10678387971099373, 0.10168236861206509, 0.09372892354517087, 0.10054121141766975, 0.11307510662137904, 0.10818904212215745, 0.11473416400049585]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
